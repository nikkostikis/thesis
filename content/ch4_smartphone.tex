\chapter{A Smartphone-based Tool for Parkinsonian Hand Tremor Assessment}
\label{ch:smartphone}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[OC]{\leftmark}
\fancyhead[EC]{\rightmark}
\cfoot{\thepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{General Approach}
\label{sec:smartGenApproach}
As discussed in section ~\ref{subsec:smartphones}, smartphones are becoming useful platforms in the hands of researchers, clinicians and medical professionals, who by developing sophisticated software and protocols can incorporate these devices into various stages of clinical practice. Even cheap devices are equipped with embedded inertial sensors, putting accelerometers and gyroscopes in the hands of every user. Combined with limitless connectivity and substantial processing power, they have the potential to become powerful quantification and monitoring tools.

Incentivized by the research discussed in ~\ref{subsec:smartphones}, including the work of LeMoyne (2010) and Deneault (2013), we set out to investigate how the sensors embedded in a smartphone would perform in a clinical setting or even home environment, and if they could provide any useful methods for \gls{PD} symptom quantification, identification and monitoring. Our approach was to use a popular smartphone device (iPhone) and incorporate it in the same setting as the normal scale-based examination, namely \gls{UPDRS} scoring, in a non-invasive, tireless manner. Having the six axes of innovation in mind (see ~\ref{sec:axes}), our objectives revolved around cost-efficiency, availability, ease of use, quality of diagnosis, effective monitoring and biobanking. 

Our approach was based on the following pillars: 

\begin{enumerate}
\item We focused on exploring the use of a ubiquitous device, such as a smartphone, with no additional software installed apart from its factory-installed operating system, and without the need to attach external hardware on it. 
\item We avoided making assumptions about the users, i.e. that they would have e-mail accounts or that they would be proficient enough to install and manage applications and configure complex settings. 
\item We explored solutions that would not require the presence of an expert to use, but would still produce replicable and accurate symptoms quantification. 
\item We opted for cloud based approaches that would ensure the persistence of the data and the availability of the results for post-processing and verification. 
\end{enumerate}

\noindent
To validate our symptoms quantification approach we conducted two separate clinical trials: 

\begin{enumerate}
\item The first was a small-scale case control pilot clinical trial (\gls{SmartCT1}), which would serve as proof-of-concept for our approach (Kostikis et al, 2011). It consisted of 10 patients with idiopathic \gls{PD}, defined as group \gls{SmartPD1}, and 10 age-matched healthy volunteers, defined as group \gls{SmartH1}. The data collected were post-processed using signal processing and statistically analyzed, to calculate quantifying metrics and establish their significance. 
\item The second was a larger case control clinical trial (\gls{SmartCT2}), were 23 patients with idiopathic \gls{PD}, defined as group \gls{SmartPD2}, and 20 age-matched healthy volunteers, defined as group \gls{SmartH2}, were recruited. In a preliminary validation study, we used the data collected from \gls{SmartPD2} to compare the quantification calculated by our tool, to the patients' \gls{UPDRS} scores (Kostikis et al, 2014). Later on, both the \gls{SmartPD2} and \gls{SmartH2} groups' data were processed and used to perform statistical analysis and build machine learning models to establish our tool's potential as a classification platform for \gls{PD} patients (Kostikis et al, 2015). During the second clinical trial we also conducted a small longitudinal trial (\gls{SmartCT2L}) recruiting two idiopathic \gls{PD} patients, defined as \gls{SmartPD2L}. They were inpatients and were screened with our tool twice, once before, and once after medication. 
\end{enumerate}

In the following section we will describe the smartphone-based clinical trials we conducted, present the data processing pipeline applied in each trial and discuss the results obtained in each case, and the implications derived from our smartphone-based \gls{PD} symptoms quantification approach. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SmartCT1}
\label{sec:SmartCT1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Protocol}
\label{subsec:SmartCT1Protocol}

\subsubsection{Rationale}
\label{subsubsec:smartCT1Rationale}
In section \ref{sec:accelerometry} we reviewed the literature proving that accelerometers are great means of studying human motor behavior and quantifying symptoms of movement disorders. In paragraph \ref{subsec:smartphones} we reviewed the papers that proved smartphones featuring Inertial Measurement Units (\gls{IMU}) sensors could be considered viable options for quantifying and measuring \gls{PD} motor symptoms.

Although accelerometers themselves and accelerometry-enabled smartphones were proven to work, the rationale of this clinical trial was to test the accuracy of a simple web-based tool in distinguishing healthy individuals from \gls{PD} patients, by assessing upper extremity rest and action postural tremor (see section \ref{subsec:tremor}) for a few seconds. Up until the inception of the trial's context by our team (late 2010), resources such as IMU sensors were only available in a mobile platform like Apple's iOS\footnote{Apple iOS, accessed 02/10/2017 at: \url{https://www.apple.com/lae/ios/}} and Google's Android\footnote{Android, accessed 02/10/2017 at: \url{https://www.android.com/}}, through native applications, developed specifically for the particular target platform. Such an application would have to be downloaded and installed to properly function. Our approach was to harness a recently available (at the time) JavaScript specification, supported in Apple's iOS 4.2 Safari browser\footnote{DeviceOrientation event specification, accessed 01/10/2017 at: \url{http://dev.w3.org/geo/api/spec-source-orientation.html}}. Opting for a web-based solution meant that the user could follow our protocol without being required to install any application or even own the mobile device. A web-based solution built on a widely adopted specification would also mean that our tool would be compatible out of the box with a vast range of devices, with varying physical characteristics and operating systems. Finally, the web-based solution allowed us to seamlessly send the collected signal upon completion of the recording, absolving the user from the responsibility to handle the data and send them via e-mail, or be involved in any other way in the signal collection and transmission. 

Another novelty at the time (late 2010) was the combination of gyroscope as well as accelerometer signals. We were specifically interested in obtaining both acceleration and rotational velocity data because observations of patients with movement disorders show that tremor in their upper extremities may have a significant rotational component.

We chose to conduct a control study and not a one-population validation study because there was complete lack of literature evidence that this method of collecting inertial signals would work, or even be robust enough for us to gather usable data, and detection of a motor anomaly should be the first step before attempting to evaluate its severity. 

Therefore, the expected outcome of \gls{SmartCT1} was to collect data using a novel tool on a small target population (\gls{SmartPD1}), examine the signals, calculate basic metrics and explore the statistical significance of the metrics when compared to a size-matched control population (\gls{SmartH1}). Most importantly, we wanted to gain significant insight concerning the optimization of the protocol of our next scheduled larger clinical trial (\gls{SmartCT2}).

\subsubsection{Volunteers}
\label{subsubsec:smartCT1Volunteers}

To conduct \gls{SmartCT1} we recruited 20 volunteers. Ten of them were healthy control subjects (\gls{SmartH1}) and 10 patients (\gls{SmartPD1}). The latter population was recruited from the outpatient clinic of the 1st Department of Neurology of AHEPA University General Hospital, located in the territory of the Aristotle University of Thessaloniki. All subjects agreed to participate in this research after a detailed explanation of its aims and of the testing procedure. Eight out of 10 volunteers of the \gls{SmartPD1} group were \gls{PD} patients. One suffered from cerebellar tremor and one had psychogenic parkinsonism. All \gls{SmartPD1} volunteers were under medication for the alleviation of their symptoms.

The inclusion criteria for the \gls{SmartH1} group was the absence of any kind of parkinsonism, whether idiopathic, atypical or secondary (see \ref{sec:parkinsonism}), both regarding themselves and their close relatives. The \gls{SmartH1} were not age-matched because our main goal was to compare pathological signals against healthy ones, and not explore the correlation between the signals collected and the patients' status. 

(\textcolor{BurntOrange}{Table X Demographics of the CT1 population}).

\subsubsection{Procedure and Hardware}
\label{subsubsec:smartCT1ProcHardware}

Although our metrics and results from \gls{SmartCT1} were not to be compared with the clinical examination mainstay, the \gls{UPDRS}, we applied the same instructions regarding body posture as described in item 3.15 - Postural tremor of the hands of the \gls{MDS}-\gls{UPDRS} (Goetz et al, 2008). More specifically, in order to assess postural hand tremor we instructed the volunteers to stretch their arms out in front of the body, keeping their palms facing the ground. The wrists were to be held straight and the fingers separated as to not touch each other, in a comfortable manner. This position was to be held for 12 seconds. Although the position is kept for 10 seconds in the directive of the \gls{UPDRS}, we opted for two more seconds to allow for errors recorded before and after each session. 

The position described above was performed while the volunteers were wearing a custom-made glove with an iPhone securely attached on it. Internet access had to be enabled on the phone, and screen orientation had to be ``locked'' to avoid mislabeling the data. We wanted to avoid having to compensate for unintentional movements, not related to the \gls{PD} symptoms, therefore we chose to keep the iPhone securely attached to the volunteers hands via a glove, and not have them hold it in their hand or place it loosely on their limbs. Having the participants hold the device would result in voluntary muscle activation, undermining the definition of postural tremor. There are studies were the patient assumes a position similar to the one described above and in the \gls{MDS}-\gls{UPDRS} item 3.15, but having the patients hold the device in their hands (Kassavetis et al, 2015). This, while efficient in the context of symptoms' quantification, ultimately cannot be comparable to results from a \gls{UPDRS} examination. This was not acceptable in our setting, where validation of our tool would be a desired outcome, requiring correlation analysis with the clinical examination ``golden'' standard, the \gls{UPDRS} at later stages of our research. 

In order to keep the presence of the smartphone as discreet as possible we built an inexpensive apparatus consisting of an elastic glove, a perforated, rigid smartphone shell case and some non-elastic thread. The result was an easy to put on and lightweight glove-case that would keep the phone attached on the patients' dorsal part of the hand, without hindering the position to be assumed, according to the procedure described earlier. Unfortunately the weight of the device at 140 grams was not trivial and could potentially slightly dampen the symptoms, but at least it was the same for all participants across our smartphone-based clinical trials and it was not something we could eradicate. 

(\textcolor{BurntOrange}{Figure consisting of three parts a. the glove, b. the case, c. some thread and d. the final custom apparatus}).

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{content/images/myHand/hand}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{content/images/myHand/figure_1_Color}
\end{subfigure}
\caption{The glove-case worn on hand with a device attached}
\label{fig:glovCase}
\end{figure}

The smartphone itself used in \gls{SmartCT1} was an Apple iPhone 4 GSM\footnote{iphone 4 technical specifications, accessed 01/10/2017 at: \url{https://support.apple.com/kb/sp587}}, powered by iOS version 4.2\footnote{iOS 4.2 software update, accessed 01/10/2017 at: \url{https://support.apple.com/kb/dl1061}}. 

\subsubsection{Software}
\label{subsubsec:smartCT1Software}
The software required for \gls{SmartCT1} consisted of the following components:

\begin{enumerate}
\item A custom made web application, built with PHP, HTML and JavaScript.
\item An Apache\footnote{Apache http server project, accessed 02/10/2017 at: \url{https://httpd.apache.org/}} web server which hosted the web application and allowed it to store simple text files.
\item A data processing pipeline written in MATLAB\footnote{Matlab, accessed 02/10/2017 at: \url{https://www.mathworks.com/products/matlab.html}} (various versions).
\end{enumerate}

The web application was designed to be as simple as possible, consisting of two views. The landing page was a simple view containing a form where the clinical trial associate or the support staff would fill in an anonymized unique identifier for the patient (Figure \ref{fig:webAppForm1}), details about the posture assumed for every recording session, which for \gls{SmartCT1} was set by default to ``Extended'' (Figure \ref{fig:webAppForm2}), and left or right hand (Figure \ref{fig:webAppForm3}). All but one the controls of the form would be hidden at first and revealed gradually to enforce a step-by-step data entry procedure, discouraging the submission of partially filled forms (Figure \ref{fig:webAppForm}). The button submitting the form would be the last one to be displayed, allowing the initiation of the collection. At that point the volunteer should already have resumed the required posture for the signal recording. 

\begin{figure}[h]
\centering
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{content/images/screens/screenA1}
  \caption{Filling in the identifier}
  \label{fig:webAppForm1}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{content/images/screens/screenA2}
  \caption{Filling in the posture}
  \label{fig:webAppForm2}
\end{subfigure}
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{content/images/screens/screenA3}
  \caption{Filling in the side}
  \label{fig:webAppForm3}
\end{subfigure}
\caption{The web application form progressive screens}
\label{fig:webAppForm}
\end{figure}

When the clinical trial associate or the support staff launched the recording, by submitting the form of the first view, the screen of the iPhone would turn red for 3 seconds (Figure \ref{fig:webApp1}) and then automatically green, showing that the collection of the signals generated by the \gls{IMU} sensors was activated (Figure \ref{fig:webApp2}). After 12 seconds (resulting in a total of 15 from the form submission), the data collected from the sensors would automatically be posted to the Apache server in the form of a text file. The text files were then gathered and handled by a series of scripts built in MATLAB, in order to be cleaned, sorted and processed to extract the metrics and study the results, as will be explained later in this manuscript. 

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.7\linewidth]{content/images/screens/screenB1}
  \caption{Form submitted, recording will start}
  \label{fig:webApp1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.7\linewidth]{content/images/screens/screenB2}
  \caption{Recording started}
  \label{fig:webApp2}
\end{subfigure}
\caption{The web application recording screens}
\label{fig:webApp}
\end{figure}

Gathering the signals generated by the smartphone's \gls{IMU} sensors was made possible via the web application by using the newly (then) adopted by mobile browsers vendors JavaScript \gls{API}s, DeviceMotion\footnote{DeviceMotionEvent, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/devicemotionevent}} and DeviceOrientation\footnote{DeviceOrientationEvent, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/deviceorientationevent}} interfaces. These are Document object model (\gls{DOM})\footnote{JavaScript HTML DOM, accessed 01/10/2017 at: \url{https://www.w3schools.com/js/js_htmldom.asp}} interfaces, called via the \codeword{window}\footnote{The window object, accessed 01/10/2017 at: \url{https://www.w3schools.com/jsref/obj_window.asp}} object. To capture DeviceMotion events the \codeword{window.onDeviceMotion} event handler\footnote{ondevicemotion, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/domwindow/1632048-ondevicemotion}} was used, whereas to capture DeviceOrientation events the \codeword{window.onDeviceOrientation} event handler\footnote{ondeviceorientation, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/domwindow/1628872-ondeviceorientation}} was used. 

The DeviceMotion interface supplied information on the acceleration of the device. Through the \codeword{event.acceleration} and \codeword{event.accelerationIncludingGravity} properties\footnote{acceleration, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/devicemotionevent/1629483-acceleration}} the acceleration of the device in three planes, $x$, $y$, $z$ (Figure \ref{fig:iphoneAxes}) was recorded in $m/s^{2}$. The maximum rate at which the interface would sample the accelerometer was a read-only property of the interface set at 20Hz.

\begin{figure}[h]
	\centering
	\includegraphics[width=.7\linewidth]{content/images/phones/iPhone_device_axes}
	\caption{iPhone 4 \& 4S accelerometer axes (source: \url{https://developer.apple.com/documentation/uikit/uiacceleration})}
	\label{fig:iphoneAxes}
\end{figure}

The DeviceOrientation interface supplied information on the physical orientation of the device. Through the \codeword{event.alpha}\footnote{alpha, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/deviceorientationevent/1629200-alpha}}, \codeword{event.beta}\footnote{beta, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/deviceorientationevent/1631254-beta}} and \codeword{event.gamma}\footnote{gamma, accessed 01/10/2017 at: \url{https://developer.apple.com/documentation/webkitjs/deviceorientationevent/1631656-gamma}} properties the angles of rotation of the device were recorded in degrees. The sampling rate of the DeviceOrientation was a read-only property and, similarly to DeviceMotion, would max out at 20Hz. 

A very important metric provided by the combination of accelerometer and gyroscope of the device and made available as a property of the DeviceMotion event was the rotation rate, recorded through \codeword{event.rotationrate.alpha}, \codeword{event.rotationrate.beta} and \codeword{event.rotationrate.gamma} in degrees per second ($^{o}/sec$). The axes of the rotation rate were defined as alpha (yaw) for the rotation around the $z$-axis, beta (roll) for the rotation around the $x$-axis and gamma (pitch) for the rotation of the device around its $y$-axis (Figure \ref{fig:iphoneAxesGyro}). 

\begin{figure}[h]
	\centering
	\includegraphics[width=.7\linewidth]{content/images/phones/iPhone_device_axes_gyro}
	\caption{iPhone 4 \& 4S gyroscope axes (adapted from: \url{https://developer.apple.com/library/content/documentation/UserExperience/Conceptual/DesigningExpandedAdUnits/FeaturesforExpandedAdUnits/FeaturesforExpandedAdUnits.html})}
	\label{fig:iphoneAxesGyro}
\end{figure}

The web application, was intended to be loaded by a device incorporating accelerometer and gyroscope. We used an iPhone 4 because it was one of the best-equipped smartphones at the time, featuring all necessary hardware and supporting the latest JavaScript specifications, as described earlier. However, the code running behind the web application was written with conditional clauses that would allow it to execute on devices lacking a gyroscope sensor, which was common at the time. When we developed the application only Apple's iOS supported the necessary \gls{API}s, but Google had recently announced that its Android operating system would also support these features in later releases. A few months later the Android version 4.4 (Kit Kat)\footnote{KitKat 4.4, accessed 02/10/2017 at: \url{https://www.android.com/versions/kit-kat-4-4/}} added the DeviceMotion and DeviceOrientation interfaces to its web browser, making every Android phone with the required sensors a suitable platform for our implementation ``out of the box''. The web application developed for \gls{SmartCT1}, apart from the JavaScript \gls{API}s gathering the accelerometer and gyroscope signal, consisted of a PHP module which created a session to hold each recording's information, and posted the values of the acceleration, orientation and rotation rate to the Apache server. The Apache server was a simple web server installed in a machine located at the University of Macedonia, operating behind a firewall. 

Functionality-wise, the clinical trial associate or the support staff would mount the iPhone on a participant's hand and load the web application. They would then fill in the necessary information in the step-by-step appearing form elements, have the participant assume the required position for the recording, and submit the form. After a delay of 3 seconds, to allow the user to feel comfortable in the position, the iPhone would start recording data via the JavaScript interfaces DeviceMotion and DeviceOrientation. After 12 seconds the web application would post acceleration and rotation data in a text file to the server, where they would be stored for post-processing. The name of the file would be a combination of the data filled in the form and a timestamp, rendering each file uniquely identifiable in the server. After persisting the file, the web application would immediately redirect to the landing page containing the form, this time already filled via the PHP session with the information of the previous recording. The staff could either choose to repeat the same recording, or put the glove in the participant's opposite hand. The payload of the web application was about 10KB and each file to be uploaded was typically less than 40KB. The web application used no local storage on the smartphone. 

Upon completion of the recordings of \gls{SmartCT1}, the files collected were all downloaded from the server to a personal computer in the University of Macedonia running MATLAB. The data in the personal computer were anonymized and the only trail of identification could be followed using the clinical trial folders containing participants' demographics, disease progression information and the unique identifier used in the web application's initial form. The separation of data and anonymity of the signals were maintained for confidentiality and security reasons. We were handling information in the context of a ``need-to-know'' basis, minimizing the chances of sensitive information being exposed. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Collected}
\label{subsec:SmartCT1Data}
During each session of \gls{SmartCT1}, participants were asked to wear the glove-case securing the iPhone on their wrist, and follow the item 3.15 protocol defined in the \gls{MDS}-\gls{UPDRS}, i.e., stretch their arms out in front of them, keeping their palms facing the ground, the wrists straight and the fingers separated, in a comfortable manner. That position was maintained for 12 seconds while data were recorded. The device was mounted on both their hands alternately, and each test was repeated at least twice for each participant. From the data obtained, we formed the participant's acceleration vector, $\alpha(i) = [\alpha_{x}(i),\alpha_{y}(i),\alpha_{z}(i)]^{T}$ (in $m/s^{2}$) and angular velocity vector $\omega(i) = [\omega_{x}(i),\omega_{y}(i),\omega_{z}(i)]^{T}$ (in $rad/s$), with $i$ denoting discrete sample and axes $x$, $y$ and $z$ defined as in figures \ref{fig:iphoneAxes} and \ref{fig:iphoneAxesGyro}. Of the 12 seconds recorded at each session the first 2 seconds were discarded. For 10 seconds signals, at 20Hz sampling rate, each session would yield 200 samples for each axis. As a first signal characteristic we calculated both for the acceleration and the rotation rate, the squared magnitude for each sample as shown in equations \ref{eq: magSampleAlpha} and \ref{eq: magSampleOmega}. Typical profiles of the two vectors (magnitude squared) are shown in figure \ref{fig:signals}.

\begin{equation} \label{eq: magSampleAlpha}
\|\alpha\|^{2} = \alpha_{x}^{2} + \alpha_{y}^{2} + \alpha_{z}^{2}
\end{equation}

\begin{equation} \label{eq: magSampleOmega}
\|\omega\|^{2} = \omega_{x}^{2} + \omega_{y}^{2} + \omega_{z}^{2}
\end{equation}

\begin{figure}[h]
\centering
\begin{subfigure}{1\textwidth}
  \centering
  \includegraphics[width=0.85\linewidth]{content/images/EMBC11/fig3a}
  \caption{Acceleration (magnitude squared) for a control volunteer compared to a \gls{PD} patient}
  \label{fig:accelSig}
\end{subfigure}

\begin{subfigure}{1\textwidth}
  \centering
  \includegraphics[width=0.85\linewidth]{content/images/EMBC11/fig3b}
  \caption{Rotation rate (magnitude squared) for a control volunteer compared to a \gls{PD} patient}
  \label{fig:rotSig}
\end{subfigure}
\caption{Acceleration and Rotation rate signal sample squared magnitudes}
\label{fig:signals}
\end{figure}

One challenge when using the DeviceMotion and DeviceOrientation JavaScript interfaces when \gls{SmartCT1} was conducted was that the sampling rate was not adjustable, and was set at a default 20Hz, which was quite low. Furthermore, sampling of the on-board devices via JavaScript was subject to jitter (in some cases we measured a jitter of up to 5ms with a nominal sampling period of 50ms). In light of these considerations, we chose to explore very simple signal metrics (e.g., energy or power) for categorizing subjects as to whether they exhibited hand tremor or not. Specifically, we computed

\begin{equation} \label{eq: magAlpha}
m_{\alpha} = \frac{\sum_{i=1}^{N} \|\alpha(i)\|^{2} }{N}
\end{equation}

\begin{equation} \label{eq: magOmega}
m_{\omega} = \frac{\sum_{i=1}^{N} \|\omega(i)\|^{2} }{N}
\end{equation}

\noindent 
where $N$ was the number of samples in the signal (i.e. 200), and attempted to categorize subjects based on these two quantities. Here $m_{\alpha}$ and $m_{\omega}$ can be viewed as signal power, the signal being the length of the acceleration and rotation rate vectors, respectively. Typical values of these metrics when the iPhone was at rest placed stationary on a desk were $m_{\alpha}=0.0127$ and  $m_{\omega}=0.0000$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Analysis}
\label{subsec:SmartCT1Analysis}
Mann-whitney non-parametric U test was used to explore the statistical significance of the difference between the $m_{\alpha}$ and $m_{\omega}$ values of the two populations. 
We first compared the mean values of $m_{\alpha}$ for our two populations, using all data (left and right hand) for each subject. Volunteers performed 2 sessions for each hand, resulting in 4 data signals. Initially, each volunteer was assigned a single number calculated as the average value of $m_{\alpha}$ for all 4 data signals collected. The \gls{SmartH1} population had an average acceleration power $m_{\alpha}$ = 0.0915 (min = 0.0338, max = 0.1325), whereas the \gls{SmartPD1} had an average acceleration power $m_{\alpha}$ = 0.1760 (min = 0.0511, max = 0.6905). Although the max value of the \gls{SmartPD1} population is quite high and the mean values are different, the min values of the two populations suggest that there is an overlap. This is obvious in the boxplot as well (figure \ref{fig:boxAllA}). As expected, the Mann-Whitney U test could not reject the null hypothesis that the distributions of the values of the two populations are different and  confirmed that it would be equally likely that a randomly selected value from the \gls{SmartPD1} population would be greater than a randomly selected value from the \gls{SmartH1} population. 

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{content/images/analysis/boxAllA}
  \caption{$m_{\alpha}$ distribution comparison}
  \label{fig:boxAllA}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{content/images/analysis/boxAllOm}
  \caption{$m_{\omega}$ distribution comparison}
  \label{fig:boxAllOm}
\end{subfigure}
\caption{Distributions comparison using volunteers' both hands' mean values}
\label{fig:boxAll}
\end{figure}


With respect to rotation rate power, the \gls{SmartH1} population had a mean of 0.0039 (min = 0.0020, max = 0.0066), whereas the average for \gls{SmartPD1} subjects was a much higher 0.0224 (min = 0.0041, max = 0.0510). In this case, the Mann-Whitney test rejected the null hypothesis with a p-value nearly equal to zero, confirming that a randomly selected value from the \gls{SmartPD1} population would most likely be larger than a randomly selected value from the control population. The boxplot confirms visually that the two distributions are different (figure \ref{fig:boxAllOm}). 

In both cases, the 10th \gls{SmartPD1} subject's scores were much higher than the rest, and were excluded when calculating the mean for the \gls{SmartPD1} group, in order to avoid ``artificially'' strong comparisons with the \gls{SmartH1} group. All values calculated as means from both hands for each volunteer are shown in table \ref{tab: allH}. 

\begin{table}
\centering
\begin{tabular}{||c c c c||} 
 	\hline
 	Col1 & Col2 & Col2 & Col3 \\ [0.5ex] 
 	\hline\hline
 	1 & 6 & 87837 & 787 \\ 
 	\hline
 	2 & 7 & 78 & 5415 \\
	\hline
	3 & 545 & 778 & 7507 \\
 	\hline
 	4 & 545 & 18744 & 7560 \\
 	\hline
 	5 & 88 & 788 & 6344 \\ [1ex] 
 	\hline
  \end{tabular}
  \caption{Numbers represent the volunteers' mean scores, using measurements from both hands}
    \label{tab:allH}
\end{table}



%--------------------------------------->>>>>>>>>>
%--------------------------------------->>>>>>>>>>
%--------------------------------------->>>>>>>>>>
%--------------------------------------->>>>>>>>>>

\hlorange{Table with values here}

As depicted in figure \ref{fig:bars1}, all \gls{SmartPD1} subjects scored higher than the control mean when considering the $m_{\omega}$ metric (in 4 cases they scored higher in both metrics).

\begin{figure}[h]
	\centering
	\includegraphics[width=.9\linewidth]{content/images/EMBC11/fig4}
	\caption{Bars represent the vlounteers' mean scores using measurements from both hands. For the $m_{\omega}$ metric the scores are scaled by 10.}
	\label{fig:bars1}
\end{figure}



The acceleration and angular velocity metrics we computed, generally agreed with the severity of hand tremor, as observed clinically. One of our goals was to see how well we can detect movement disorders (in this case, hand tremor) using $m_{\alpha}$ and $m_{\omega}$. Towards that end, we explored the possibility of identifying subjects with hand tremor via two simple criteria. The first was whether either of a subject's mean measurements ($m_{\alpha}$, $m_{\omega}$) were above a certain threshold, namely the highest mean score encountered in the \gls{SmartH1} group. Because it is known that \gls{PD} typically affects one side of the patient more severely than the other, we re-calculated each metric using data only from each subject's ``worst-performing'' hand, i.e., the hand which scored highest in each metric. By doing so, the highest acceleration and rotation rate scores for healthy subjects were 0.1515 and 0.0092, respectively. The identification of patients’ worst-performing hands by comparing average metrics for their left vs. right hand as described above, gave the same results regardless of the metric used (acceleration or rotation rate), and correctly identified the worst hand of every patient except volunteer number 4. The comparisons between the subjects' mean scores for their worst-performing hand and the thresholds (maximum scores) obtained from the control group are described in figure \ref{fig:bars2}. The thresholding criterion correctly ``labels'' nine of the ten subjects as being in the \gls{SmartPD1} group. The one exception was volunteer number 8 who does suffer from \gls{PD}, but his symptoms include mostly bradykinesia and rigidity, as opposed to pronounced hand tremor. We note that if we were to judge based on  $m_{\omega}$ alone, then the same nine subjects would be true positives, whereas only four subjects exceeded the $m_{\alpha}$ acceleration threshold. 

\begin{figure}[h]
	\centering
	\includegraphics[width=.9\linewidth]{content/images/EMBC11/fig5}
	\caption{Bars represent the volunteers' mean scores using measurements only from worst-performing (highest-scoring) hand. For the $m_{\omega}$ metric the scores are scaled by 10.}
	\label{fig:bars2}
\end{figure}

A second criterion for comparing the \gls{SmartPD1} and \gls{SmartH1} populations was the difference between hands for both $m_{\alpha}$ and $m_{\omega}$. A healthy volunteer would not be expected to have very different left versus right mean scores, while the opposite is often true for patients with parkinsonism. Regarding $m_{\alpha}$, the control group had an average hand-to-hand difference of 0.0232 (max=0.0514, min=0.0123, std. dev.=0.0117) whereas \gls{SmartPD1} participants had an average difference of 0.1572 (std. dev.=0.2629). The corresponding numbers for $m_{\omega}$ were 0.0031 (max=0.0053, min=0.0006, std. dev.=0.0016) for the \gls{SmartH1} group and 0.0185 (std. dev.=0.0147) for the \gls{SmartPD1} group. Again, nine of the patients had mean differences which exceeded the maximum encountered in the healthy group in either $m_{\alpha}$, $m_{\omega}$, or both; they were the same nine identified via thresholding on worst-hand scores.


%Implications and conclusion

The purpose of this first study was to collect data by integrating a smartphone, as seamlessly as possible, into the specific item of the gold standard of clinical evaluation, i.e., \gls{UPDRS}, which is used to assess postural tremor, and to explore whether these data could have value in quantifying and identifying \gls{PD} related tremor. 

We explored the use of recently-available smartphone technology for the purpose of diagnosing and quantifying the postural tremor which characterizes movement disorders such as Parkinson’s disease. Our method is based on the use of on-board accelerometer and gyroscope which are currently found in many smartphones and can be accessed via the web. Unlike previously proposed approaches, ours i) is web-based, meaning that the user simply visits a web page without installing software on their phone, or handling the data being collected, and ii) uses accelerometer and gyroscope data simultaneously in order to classify patients based on very simple signal metrics and thresholding. 
We tested our approach in a small clinical trial involving twenty subjects (half of them being the control group) and found that we correctly categorize nine of the ten patients, based on the power of their acceleration and rotational velocity signals, or the differences in performance between their two hands. The gyroscope data appear to be particularly useful in that regard.
Our goal is to ultimately make our web application freely available on a dedicated server which will receive data and return the results to the user and their physician (securely, over SSL), for the purposes of providing remote diagnostic decision support and tracking of the patient’s condition over time. Towards that end, we are currently in the process of evaluating our approach in larger trials, with data obtained from additional types of subject movements and postures, alternative signal metrics, and comparison of the resulting scores to the patients’ UPDRS ratings. 
The fact that we are using a JavaScript API to control the smartphone’s hardware (as opposed to its native programming platform) does give us flexibility but deprives us of certain benefits such as adjusting the sampling rate. To circumvent this problem, we are also pursuing an Objective C application which will be used to repeat the same clinical tests for comparison, as well as more sophisticated signal processing methods (including reconstruction for irregularly sampled signals [14], [15]). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SmartCT2}
\label{sec:SmartCT2}

Although our metrics and results from \gls{SmartCT1} were not to be compared with the clinical examination mainstay, the \gls{UPDRS}, we applied the same instructions regarding body posture as described in items 3.15 - Postural tremor of the hands and 3.17 - Rest tremor amplitude of the \gls{MDS}-\gls{UPDRS} (Goetz et al, 2008). More specifically, in order to assess postural hand tremor we instructed the volunteers to stretch their arms out in front of the body, keeping their palms facing the ground. The wrists were to be held straight and the fingers separated as to not touch each other, in a comfortable manner. This position was to be held for 12 seconds. To assess rest tremor we instructed the volunteers to sit comfortably in a chair, with their arms placed on the arms of the chair, without touching their lap, and their feet loosely placed on the floor. This position was to be held for 12 seconds, as well. Although both positions are kept for 10 seconds in the directive of the \gls{UPDRS}, we opted for two more seconds to allow for errors recorded before and after each session. 

The positions described above were performed while the volunteers were wearing a custom-made glove with an iPhone securely attached on it. Internet access had to be enabled on the phone, and screen orientation had to be ``locked'' to avoid mislabeling the data. We wanted to avoid having to compensate for unintentional movements, not related to the \gls{PD} symptoms, therefore we chose to keep the iPhone securely attached to the volunteers hands via a glove, and not have them hold it in their hand or place it loosely on their limbs. Having the participants hold the device would result in voluntary muscle activation, undermining the definition of postural and rest tremor. There are studies were the patient assumes a position similar to the one described above and in the \gls{MDS}-\gls{UPDRS} item 3.15, but having the patients hold the device in their hands (Kassavetis et al, 2015). This, while efficient in the context of symptoms' quantification, ultimately cannot be comparable to results from a \gls{UPDRS} examination. This was not acceptable in our setting, where validation of our tool would be a desired outcome, requiring correlation analysis with the clinical examination ``golden'' standard, the \gls{UPDRS} at later stages of our research. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Protocol}
\label{subsec:SmartCT2Protocol}

The regimen that had to be followed during all smartphone-based clinical trials was the same, albeit a few minor modifications after the first trial. 

At the server, the data are processed to extract information about possible movement disorders. Currently, that processing is done via a separate MATLAB application; however, our plan is to integrate its execution into the website, so that the results may be automatically obtained and communicated back to the user and/or their physician.  


\subsubsection{Rationale}
\label{subsubsec:smartCT2Rationale}
Researchers frequently look for new ways to facilitate the work of physicians and doctors, for the purposes of increased accuracy, speed or accessibility. Towards that end, smartphones and smartphone-like devices offer a tantalizing platform since they contain embedded motion sensors, including accelerometers and gyroscopes, making it possible to detect even slight displacements of the device. Moreover, phones that feature such sensors are now commonplace, and it is relatively easy to utilize a smartphone to detect movement anomalies that appear in disorders such as Parkinson’s disease. Accelerometers have been used successfully for characterizing tremor [1] and are particularly useful in measuring “resting” tremor (i.e., with the patient’s hand being at rest against their body), and thus objectively quantifying one of the condition’s predominant attributes. However, the advent of new technology does not remove the need for existing qualitative clinical assessment methods administered by a physician; on the contrary, it appears that clinical assessment will continue to be a mainstay in the diagnosis and tracking of movement disorders. Concerning Parkinson’s disease in particular, clinical assessment typically uses the so-called UPDRS (Unified Parkinson’s Disease Rating Scale) scoring method [2], in which the physician assigns numerical scores based on qualitative observations of the patient in various postures. 

This paper is a continuation of our previous work [3]; its main contribution is a statistical comparison between signal-based methods of quantifying Parkinsonian tremor using a smartphone, and the UPDRS scores assigned by a physician specialist, in order to validate our previous approach. We acquired hand tremor signals from twenty-three patients using an iPhone and computed the correlation (Pearson product-moment) between the metrics under consideration and the patients’ UPDRS scores regarding hand tremor. Our results indicate a strong correlation (r>0.7) with high statistical significance (p<0.01), which suggests that our quantitative methods of measuring Parkinsonian hand tremor [3] show promise as a means of systematically tracking that component of the disease, possibly as part of a clinical exam or in telemedicine applications. 

The use of the embedded sensors in smartphones has introduced new accessibility options, without sacrificing efficiency, with the added bonus of the gyroscope, which is present in an increasing number of devices. LeMoyne et al. [15] were the first to introduce the use of a smartphone to collect acceleration data through an application installed on the device and send the data via e-mail to a remote computer for post-processing. 
In earlier work [3], we used [15] as a starting point and built a similar smartphone-based diagnostic tool for the detection and tracking of movement disorders. The novelty of our effort was that it was completely web-based, requiring from the patient nothing more than tapping on a web link while having the phone mounted on his/her hand. Moreover, ours is the only implementation that uses both the accelerometer and the gyroscope embedded in a smartphone. Being web-based, our tool [16] is independent of the operating system on the device and works on iPhone as well as on Android v4.4 devices. 

The authors of [17] took a very similar approach to ours: an application collects the acceleration data from an iPhone and posts them online for assessment, while the presence of a physician on site is not necessary. More recently, other researchers used a BlackBerry Storm phone to measure tremor, implementing the signal processing algorithms on-board the device with good results [18]. 

%JBHI Rationale

(PD) is a chronic neurodegenerative disorder, affecting more than 1\% of people over 55 and more than 3\% of those over 75 years of age [1]. It is caused by low and falling dopamine levels. Its symptoms are extensively documented, including tremor, bradykinesia, rigidity, postural instability and impaired cognitive function [2], however the reason why the dopaminergic neurons die (resulting in abnormally low dopamine levels) is unknown. Thus, current treatments only focus on alleviating the symptoms and improving the patients’ daily life. 
The typical clinical examination of a PD patient involves a standardized procedure where the physician evaluates the performance of the patients on a scale of 0-4, observing them in postures and tasks described in the Unified Parkinson’s Disease Rating Scale (UPDRS) [3]. When motor impairment is present, physicians may use the results of Electromyography (EMG) or imaging scans such as Positron Emission Tomography (PET) and Single-Photon Emission Computed Tomography (SPECT) to exclude other reasons for the symptoms before diagnosing PD, but these techniques do not constitute PD assessment tools per se. 
Tremor is not the main quality of life constraining-aspect of the disease [4], but responds well to dopaminergic medication; as such, its objective quantification can provide useful feedback on the efficacy of the treatment regimen. Because of that, researchers have turned to platforms involving wearable accelerometers to help them assess PD tremor, with relative success [5],[6],[7],[8],[9]. 
When it comes to PD, it is important to be able to assess patients accurately and frequently in order to adjust their treatment as necessary when variations in the severity of the symptoms occur. Unfortunately, in addition to the time and costs involved, it is difficult for most patients (even more so for those in rural areas), to be monitored frequently by a specialized physician. This creates the need for tools that can aid the physician by assessing a patient’s condition remotely, and that are practical and easy to use. 
In the last few years, researchers have explored the ability of smartphones to quantify PD tremor accurately [10],[11],[12]. These devices are now ubiquitous with a suite of on-board sensors (including accelerometers) and wireless connectivity. They are also easy to use compared with most wearable accelerometer solutions previously developed. As such, they have been making their way into medical research aimed at developing mobile tools for aiding the physician [13]. 
Although scientifically important, none of the accelerometer- or smartphone-based methods proposed to date have made their way into mainstream clinical practice. The last decade there have been efforts to create platforms incorporating inertial measurement sensors into scalable body sensor networks, with wireless connectivity and real-time on-node signal processing. Approaches like SHIMMER, Kinesia and Xsens do provide researchers with valuable information, however they have high complexity in terms of hardware and software, high cost, and lack standardized, approved and widely accepted protocols. Additionally, they can hardly be considered ubiquitous. 
The goal of this work is to investigate the use of a smartphone-based tool for assessing PD induced hand tremor. Our approach involves using the phone’s embedded accelerometer and gyroscope sensors to quantify PD hand tremor. Operationally, the patient simply visits a web site [14] and takes up simple postures much like those used in standardized clinical exams, with the smartphone mounted on their hand. The data thus recorded can then be used to classify a subject as healthy or not, and to track the severity of the tremor in PD patients. 
Preliminary versions of this work can be found in [15] and [16], where we presented proof-of-concept results for the tool discussed here. This paper substantially differs from and extends our previous work by i) including additional samples from healthy subjects which are age-matched to the PD patients used in our study, ii) including data on a small sample of patients off medication in order to quantitatively track the severity of their hand tremor, iii) exploring the correlation between our quantitative metrics results and the patients’ (subjective) clinical examination for all supported postures, and iv) using a machine learning feature classification approach to choose those metrics which are better at distinguishing between pathological and healthy signals, thus  increase our method’s accuracy. The accuracy in separating healthy from PD subjects attained in this work is on par with other works using smartphones’ accelerometers and short-duration data [12]. It is also very close to the sensitivity and specificity achieved in [17], where the authors used sensors of the SHIMMER platform to perform mobile gait analysis. There are works that achieve near 100\% accuracy but do so using day-long signals [18] which may not be practical in our setting. High accuracy (98.5\% sensitivity, 97.5\% specificity) is also achieved using smartphone accelerometer-based gait analysis, with a combination of tests and metrics [19]. 
The proposed method has been implemented in the form of an app and is available for use on any smartphone with iOS or Android installed, without the need for any downloads or memory-consuming installations [14]. It can be offered as a web-service, so that developers can build their own applications around it and extend its functionality. Our approach does not require the presence of an expert or any kind of special equipment to conduct measurements. It transmits data in real time via TCP/IP, connecting the patient to his physician with no delays, and can benefit the research community by providing anonymized information on PD hand tremor profiles. 

The remainder of this paper is structured as follows. In Section II we describe our experimental setup, the subjects used in our study and the metrics calculated based on the signal(s) collected from each subject. Section III contains the main results, including statistical analyses of the subjects’ scores under each metric, correlation with the subjects’ clinical “picture”, and a machine-learning-based discrimination scheme for separating healthy from PD subjects. Section IV summarizes our findings and discusses their implications for medical practice, as well as future work.

\subsubsection{Volunteers}
\label{subsubsec:smartCT2Volunteers}
The twenty-three subjects participating in this study were all Parkinson's disease patients recruited from the outpatient clinic of the 1st Department of Neurology at the Aristotle University of Thessaloniki. All agreed to participate in this research after a detailed explanation of its aims and of the testing procedure. All patients were under treatment. In this work we are initially interested in resting tremor so we asked the subjects to ``wear'' an iPhone (fitted on a glove as in [3]) on top of their hand while sitting in a chair comfortably and resting both their hands on their lap, keeping that position for 30 seconds. The device was mounted on both their hands alternately, and each test was repeated twice for each subject. Immediately prior to data collection, an experienced physician examined each subject and recorded their UPDRS scores, which were to be correlated with our quantitative measurements. 

\subsubsection{SmartCT2L Rationale}
\label{subsubsec:smartCT2LRationale}
The 23 volunteers of the PD group who underwent the smartphone-based tremor measuring procedure were under medication, but the timespan from their last dose of L-DOPA was anywhere from 1 to 4 hours when they were tested. That means that some of them were at the peak of the drug’s effect while for others this was not the case. With an eye towards tracking the progression of PD, we wanted to see how our metrics would “react” to an alteration in a patient’s condition, such as that brought on by medication intake. We observed two PD volunteers, referred to as the PDDN group, who stayed in the clinic overnight and followed our experimental protocol both “off” and “on” medication (i.e., right before taking their medication in the morning and one hour after that). In Table VI we present the percent differences “on”-“off” in the four metrics, along with the UPDRS scores (“off” and “on”) for both PDDN subjects. We would expect those differences to be negative because we expect higher metric scores (more pronounced tremor) while off-medication or in a de novo state, and lower after the drug ingestion (“on”). 
From the UPDRS scores of the two volunteers it is clear that these two patients did not suffer from severe hand tremor. Their physician observed that the medication improved mostly the patients’ rigidity (which is not measured by our tool) and less so their tremor. However, it is encouraging to note that the readings of the smartphone’s sensors respond well and follow the expected negative trend of the changes in the UPDRS scores in the “on” state. The only discrepancy is observed in the eR position of volunteer B for all metrics, however for that position there were also no observed clinical changes in the UPDRS “on”-“off” as well. 

\subsubsection{SmartCT2L Volunteers}
\label{subsubsec:smartCT2LVolunteers}
We recruited twenty-five PD patients from the outpatient clinic of the 1st Department of Neurology at the Aristotle University of Thessaloniki. They all agreed to participate after they were offered a detailed explanation of the study’s procedure and goals. All of them were right-handed, under L-DOPA treatment and suffering from PD for more than two years. During the study, two of them were hospitalized overnight so that they could be tested in the morning before they received their medication, to approximate de novo PD patients. Those two will be referred as our PDDN group, while the PD group comprises the other twenty-three (see Table I for patients’ information). 
The control group for the study, labeled as group H, contains twenty healthy volunteers, none of whom suffered from a movement disorder, hypertension or diabetes. They were screened for several health conditions which could exclude them from the study, such as hypertension or any movement disorder. They were also notified of the procedure and the purpose of the study before agreeing to participate. Grouping information on all participants of the study is provided in Table II. 
The ages of the two main groups were mean-tested with the non-parametric Mann-Whitney test and were found not to be statistically different at the 1\% significance level, therefore the groups can be considered age-matched. 

\subsubsection{Hardware And Software Setup}
\label{subsubsec:smartCT2SetUp}
In this work we are initially interested in resting tremor so we asked the subjects to “wear” an iPhone (fitted on a glove as in [3]) on top of their hand while sitting in a chair comfortably and resting both their hands on their lap, keeping that position for 30 seconds. The device was mounted on both their hands alternately, and each test was repeated twice for each subject. Immediately prior to data collection, an experienced physician examined each subject and recorded their UPDRS scores, which were to be correlated with our quantitative measurements. 
The work in [3] used 12-second recorded signals. Here, we decided to increase the duration to 30 seconds after experimentation that showed that the longer signal gave vastly improved results under spectral analysis.

We attached an iPhone on our volunteers’ hands using the same custom-made mounting glove (Fig. 1) from [15] and [16]. It consists of a perforated case into which the phone “locks”, and a wrist-supporting glove, both commercially available. The glove fits tightly on the volunteer’s hand and the case is tightly sewn on the glove using non-elastic thread, ensuring the stability of the device on top of the hand. With the device attached, each participant had to maintain each of two prescribed postures for 30 seconds, while acceleration and gyroscope data was recorded by the phone. The two postures we used were the same ones used during the clinical evaluation: a) “Extended”, i.e., seated with both hands extended in front of the torso (Postural Tremor of the Hands, component 3.15 of the MDS-UPDRS) and b) “Rest”, i.e., seated with both hands placed on the arms of the chair (Rest Hand Tremor, component 3.17 of the MDS-UPDRS). The procedure was then repeated for the subject’s other hand, in the same two postures. In the following, we will specify the combination of a patient’s hand (Right of Left upper extremity) during each position as rR, rL, eR, and eL for rest-right, rest-left, extended-right, and extended-left, respectively.

As per the protocol described earlier, the volunteers were asked to maintain certain postures for 30 seconds, during which the application automatically collected the accelerometer and gyroscope data and sent them to our server. We then used the data to extract features which quantify and characterize the subjects’ tremor levels. The signals were sampled at 20Hz, which is sufficient to identify events occurring at 9Hz or less [20], such as PD-induced tremor. 

Our setup consists of four essential components:
1. An iPhone 4 with iOS 4.2 or later, with Internet access enabled,
2. A web site which collects data from the phone’s sensors when visited by the user,
3. A web server which  hosts the site and stores measurements,
4. Software for processing the signals received at the server.



To collect our acceleration and rotational velocity signals for this work we used a setup similar to [3]:
1.	An iPhone 4S with iOS 6 or later, with Internet access enabled,
2.	A web site to collect data from the phone’s sensors,
3.	A web server to host the site and store the measurements,
4.	Software for processing the signals received at the server.
The work in [3] used 12-second recorded signals. Here, we decided to increase the duration to 30 seconds after experimentation that showed that the longer signal gave vastly improved results under spectral analysis. Once the recording of the accelerometer and gyroscope readings is done, the data are transmitted to the server as simple text files for post processing. 
 

The UPDRS scores of the PD volunteers were assessed by the same physician (our third author), just before data collection. We attached an iPhone on our volunteers’ hands using the same custom-made mounting glove (Fig. 1) from [15] and [16]. It consists of a perforated case into which the phone “locks”, and a wrist-supporting glove, both commercially available. The glove fits tightly on the volunteer’s hand and the case is tightly sewn on the glove using non-elastic thread, ensuring the stability of the device on top of the hand. With the device attached, each participant had to maintain each of two prescribed postures for 30 seconds, while acceleration and gyroscope data was recorded by the phone. The two postures we used were the same ones used during the clinical evaluation: a) “Extended”, i.e., seated with both hands extended in front of the torso (Postural Tremor of the Hands, component 3.15 of the MDS-UPDRS) and b) “Rest”, i.e., seated with both hands placed on the arms of the chair (Rest Hand Tremor, component 3.17 of the MDS-UPDRS). The procedure was then repeated for the subject’s other hand, in the same two postures. In the following, we will specify the combination of a patient’s hand (Right of Left upper extremity) during each position as rR, rL, eR, and eL for rest-right, rest-left, extended-right, and extended-left, respectively.
The hardware setup was the same as the one used in our earlier work, [15] and [16]: 
1.	An iPhone 4S with the latest iOS, with Internet access enabled, and screen orientation ``locked'' in vertical,
2.	A web application to collect data from the smartphone’s sensors,
3.	A web server to host the site and store the signals, and
4.	A MATLAB application for processing the signals received at the server.
As per the protocol described earlier, the volunteers were asked to maintain certain postures for 30 seconds, during which the application automatically collected the accelerometer and gyroscope data and sent them to our server. We then used the data to extract features which quantify and characterize the subjects’ tremor levels. The signals were sampled at 20Hz, which is sufficient to identify events occurring at 9Hz or less [20], such as PD-induced tremor. 
Our web application, being written in PHP and JavaScript, is entirely independent of the client's hardware or software platform. It only demands basic prerequisites such as an embedded accelerometer and gyroscope and one of the most popular smartphone operating systems, iOS or Android. We successfully tested it on a Samsung Galaxy S4 and a Google Nexus 5, both running Android 4.4.2. 



$\alpha(i) = [\alpha_{x}(i),\alpha_{y}(i),\alpha_{z}(i)]^{T}$
$\omega(i) = [\omega_{x}(i),\omega_{y}(i),\omega_{z}(i)]^{T}$

%Equations

\begin{equation} \label{eq: magAlpha2}
mag_{\alpha} = \sum_{i=1}^{N} \|\alpha(i)\|^{2}
\end{equation}

\begin{equation} \label{eq: magOmega2}
mag_{\omega} = \sum_{i=1}^{N} \|\omega(i)\|^{2}
\end{equation}

\begin{equation} \label{eq: sdAlpha}
sd_{\alpha} = \sum_{i=1}^{N-1}\sum_{\kappa \in \{x,y,z\}} |\alpha_{\kappa}(i) - \alpha_{\kappa}(i+1)|
\end{equation}

\begin{equation} \label{eq: maxAmpOmega}
mAmp_{\omega} = \sum_{\kappa \in \{x,y,z\}} \max_{4 \leq \xi \leq 7} \hat{\omega}_{\kappa}(\xi)
\end{equation}



%i) including additional samples from healthy subjects which are age-matched to the PD patients used in our study, ii) including data on a small sample of patients off medication in order to quantitatively track the severity of their hand tremor, iii) exploring the correlation between our quantitative metrics results and the patients’ (subjective) clinical examination for all supported postures, and iv) using a machine learning feature classification approach to choose those metrics which are better at distinguishing between pathological and healthy signals, thus  increase our method’s accuracy. The accuracy in separating healthy from PD subjects attained in this work is on par with other works using smartphones’ accelerometers and short-duration data [12]. It is also very close to the sensitivity and specificity achieved in [17], where the authors used sensors of the SHIMMER platform to perform mobile gait analysis. There are works that achieve near 100\% accuracy but do so using day-long signals [18] which may not be practical in our setting. High accuracy (98.5\% sensitivity, 97.5\% specificity) is also achieved using smartphone accelerometer-based gait analysis, with a combination of tests and metrics [19]. 
%The proposed method has been implemented in the form of a website and is available for use on any smartphone with iOS or Android installed, without the need for any downloads or memory-consuming installations [14]. It can be offered as a web-service, so that developers can build their own applications around it and extend its functionality. Our approach does not require the presence of an expert or any kind of special equipment to conduct measurements. It transmits data in real time via TCP/IP, connecting the patient to his physician with no delays, and can benefit the research community by providing anonymized information on PD hand tremor profiles. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Signal and Metrics}
\label{subsec:smartSignalMetrics}
%For each volunteer’s session we obtained two signals from the phone’s sensors, the acceleration vector 〖α(i)=[α_x (i),α_y (i),α_z (i)]〗^T (in m/s2) and the  rotational velocity vector 〖ω(i)=[ω_x (i),ω_y (i),ω_z (i)]〗^T (in deg/s), with i denoting discrete time. The rotational velocity in practice should be more information-rich because it is constructed using both accelerometer and gyro data and is expected to capture more of the characteristics of the tremor. We applied a band-pass filter with cutoff frequencies of 1.5Hz and 9.5Hz, in order to exclude noise due to breathing, pulse, or any high-frequency sudden movements during the recordings. The spectral analysis of α(i) and ω(i) of a PD volunteer with typical Parkinsonian tremor is shown in figure 2. As expected, her acceleration and rotational velocity signal amplitude peaks at about 3-5Hz, which is consistent with the literature [20]. We used the acceleration and rotational velocity signals as in [16], to compute the following four metrics for each session:
%where: 〖mag〗_α and 〖mag〗_ω are the sums of squared magnitudes of the acceleration, and the rotation rate vector respectively, and 〖sd〗_α, is the sum of absolute differences in the acceleration vector, summed over each of the three axes, x, y, and z. To compute the 〖mAmp〗_ω metric (4) we initially obtained the magnitude of the Fourier transform of each of the three axial components of the rotation vector ω(i), defined as (ω_κ ) ̂(ξ), κ∈{x,y,z}. We then determined each component’s maximum in the 4≦ ξ ≦7 Hz range (that range being consistent with the frequency of Parkinsonian tremor) and summed the three maxima [16]. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Signal Processing}
\label{sec:smartSignalProcessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Means Testing}
\label{subsec:smartMeansTesting}
%Since our goal is to facilitate monitoring and diagnosis of PD-induced tremor, it is essential to establish that the metrics described in the previous section can be useful in differentiating the PD vs H populations. We used the non-parametric Mann-Whitney test to establish that the two populations have statistically different means in all four metrics on all four postures, rR, rL, eR, eL. As shown in Table III, all between-groups tests found significant differences between the mean scores of the metrics of the H volunteers compared to the mean of the PD volunteers. This suggests that the two populations (H and PD) have statistically different scores under every one of the signal metrics computed, and one may attempt to differentiate H vs PD subjects based on one or more of those metrics.
% There was no statistical difference in the subjects’ left vs. right mean scores within each group (see Table IX in Appendix). It is typical for PD patients to manifest the disease’s symptoms with some laterality, i.e., to a greater degree on one side, right or left. That is indeed the case with our PD volunteers because 19 of the 23 have differences between the sums of the UPDRS components concerning right vs left hand tremor indicating laterality of motor impairment. Although clinically observable, the Mann-Whitney test for the summed UPDRS scores for right vs left hands yields no statistical difference, with p=0.7327. In order to identify the laterality statistically, for each metric we summed the scores of both postures for right and left hand separately and calculated the absolute differences between them. As shown in the last four rows of Table III, for each metric, the absolute differences between hands for the PD group is statistically different from those of the H group. That means that the amount of difference between hands is not the same for PD and H, presumably due to the disease’s laterality.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Features Identification}
\label{subsec:smartFeaturesIdentification}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Correlation with Scale-based Metrics}
\label{subsec:smartCorrelation}
%In previous work [16] we attempted to establish the validity of our smartphone-based method of upper limb parkinsonian tremor quantification by running a Pearson product-moment correlation analysis between the UPDRS scores of the PD volunteers and their respective signal metrics. Table IV contains the results of the correlation analysis for the Rest posture scores. The numbers are slightly different from our previous study because the signals are now band pass filtered, as previously explained. In [16] we used the Rest posture data only, whereas here we were also interested in the Extension posture data for both hands. The correlation analysis of the Extension posture data (Table V) yields low coefficients (r<0.6) with low confidence (p>0.01). The results are better for the right hand but generally do not suggest good correlation between the UPDRS scores and the smartphone metrics. These findings show a connection between the manifestation of the action hand tremor and the hardware experimental setup. The fact that the resting tremor is identified consistently, whereas in the extended posture the measured tremor correlates weakly with the clinical assessment, is probably related to the effect of the mass of the smartphone on the dynamics of the hand/arm system.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Machine Learning Model}
\label{sec:smartMachineLearning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{sec:smartDiscussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{OFF - State Trials}
\label{subsec:smartOffState}
%The 23 volunteers of the PD group who underwent the smartphone-based tremor measuring procedure were under medication, but the timespan from their last dose of L-DOPA was anywhere from 1 to 4 hours when they were tested. That means that some of them were at the peak of the drug’s effect while for others this was not the case. With an eye towards tracking the progression of PD, we wanted to see how our metrics would “react” to an alteration in a patient’s condition, such as that brought on by medication intake. We observed two PD volunteers, referred to as the PDDN group, who stayed in the clinic overnight and followed our experimental protocol both “off” and “on” medication (i.e., right before taking their medication in the morning and one hour after that). In Table VI we present the percent differences “on”-“off” in the four metrics, along with the UPDRS scores (“off” and “on”) for both PDDN subjects. We would expect those differences to be negative because we expect higher metric scores (more pronounced tremor) while off-medication or in a de novo state, and lower after the drug ingestion (“on”). From the UPDRS scores of the two volunteers it is clear that these two patients did not suffer from severe hand tremor. Their physician observed that the medication improved mostly the patients’ rigidity (which is not measured by our tool) and less so their tremor. However, it is encouraging to note that the readings of the smartphone’s sensors respond well and follow the expected negative trend of the changes in the UPDRS scores in the “on” state. The only discrepancy is observed in the eR position of volunteer B for all metrics, however for that position there were also no observed clinical changes in the UPDRS “on”-“off” as well.
