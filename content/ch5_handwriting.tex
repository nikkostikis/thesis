\chapter{Parkinson's Symptom Quantification via Simple Drawing and Handwriting Markers}
\label{ch:handwriting}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[OC]{\leftmark}
\fancyhead[EC]{\rightmark}
\cfoot{\thepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{General Approach}
\label{sec:PenGenApproach}
As discussed in section \ref{sec:handwriting}, handwriting-related tasks have been proven to work reasonably well in identifying and quantifying abnormal patterns in \gls{PD} patients. There are two phenomena defined and related with \gls{PD} pathology:

\begin{itemize}
\item Micrographia, which entails the reduction in size of the lettering of the writer in comparison with his writing style before the disease onset (Wilson, 1925). There are two types, the consistent micrographia, where there is a global reduction in lettering size, and the progressive, where the writer gradually produces smaller letters after writing a few characters. Micrographia has not been found to be directly related to any other particular \gls{PD} symptom. The consistent type is responsive to levodopa, whereas the progressive one is medication resistant. 
\item Dysgraphia, which includes any abnormal behavior in the mechanics of handwriting skills (Letanneux et al, 2014). Researchers believe that all motor impairments of \gls{PD}, such as the \gls{TRAP} complex, reduced visuospatial perception, and motor coordination deficiencies can actually contribute to pathological handwriting kinematics, in combination with and beyond writing size. 
\end{itemize}

\noindent
The dysgraphia ``umbrella'' term implies that the same motor impairments responsible for micrographia could manifest and be detectable through much simpler tasks than writing text, like drawing lines and shapes, and even when actual micrographia is not yet detectable. Given the fact that micrographia can already be detected up to four years earlier than the cardinal \gls{PD} symptoms like tremor or rigidity even becoming observable through the \gls{UPDRS} clinical examination, dysgraphia could be a very promising measure for early detection. 

Of course, due to the simplistic nature of the tasks involved, dysgraphia assessment requires more sophisticated signal processing, feature extraction protocols and algorithms to be applied, in order to unveil and isolate the useful information from the simple drawing movements. Signal analysis must go beyond calculating stroke size and duration to identify discriminating characteristics and reveal early and subtle impairments.

Our approach to detect dysgraphia-related impairment was based on the following pillars: 

\begin{enumerate}
\item We focused on exploring the use of a simple off-the-shelf electronic device, such as a tablet digitizer attached to a consumer grade computer, with no exotic specifications or dedicated hardware required.  
\item We avoided requiring the users to follow any particular training to use our system. 
\item We devised a system that would not require the presence of an expert to use, but would still produce replicable and accurate symptoms quantification. 
\item We opted for a task that could be performed by both hands and would be simple enough to not be affected by the innate dexterity of the dominant hand.
\item To favor simplicity and ubiquity, we removed the complexity from the signal collection and focused instead on the signal processing protocol.  
\end{enumerate}
%I'm particularly proud of that list (!)
\noindent
To validate our dysgraphia quantification approach we conducted a clinical trial (\gls{PenCT}). It consisted of 24 patients with idiopathic \gls{PD}, defined as group \gls{PenPD}, 20 age-matched healthy volunteers, defined as group \gls{PenH}, and 15 younger healthy volunteers, defined as gls{PenYH}.

\hlorange{power analysis?}

The data collected were post-processed using signal processing techniques and statistically analyzed, to calculate quantifying metrics and establish their significance. We also experimented training and testing machine learning algorithms using the data collected, to be able to classify new unlabeled trajectories as drawn by healthy individuals or \gls{PD} patients. 

In the following section we will describe the tablet-based clinical trial we conducted, present the data processing pipeline applied, and discuss the results obtained and the implications derived from our tablet-based \gls{PD} symptoms quantification approach. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PenCT}
\label{sec:PenCT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Protocol}
\label{subsec:PenCTProtocol}

\subsubsection{Rationale}
\label{subsubsec:PenCTRationale}
In section \ref{sec:handwriting} we reviewed the literature proving that handwriting and drawing tasks can be used to study human upper limb motor behavior and monitor movement disorders' symptoms in quantitative way. 

Writing is a skill that is developing later in a child's life. It involves a complex feedback system, integrating continuous information from the writing hand, i.e., proprioceptive sensory stimuli from all muscles involved, and sensory information from the fingers and the visual system. Also, writing is a task that implicates the participation of various degrees of cognitive processes. Researchers have tried to isolate the motor aspect of the task and minimize the involvement of any cognitive process that could affect the patient's performance and have used the Archimedes spiral, single letters or simple words, in order to investigate purely motor aspects of handwriting (Saunders-Pullman et al, 2008). In (Popovic et al, 2008) the authors showed that even simpler tasks, namely drawing point-to-point trajectories, contained useful features that helped detect motor blocks in \gls{PD} patients.

For the \gls{PenCT} study we picked up from (Popovic et al, 2008) designed a protocol that would use tasks stripped of cognitive involvement, as much as possible, easily executable with both hands, and requiring no particularly special equipment or hardware setup. We were interested in keeping the signal collection simple, fast, easy for elderly people, requiring minimum instruction and training, and suffering from low probability of erroneous execution. The layman's task would mean the data processing would have to be sophisticated enough to extract metrics containing significant information, sufficient for classification. 

We explored the use of a simple line-drawing task. Line-drawing would be simpler than, for example, writing or drawing spirals, would last only a few seconds, would involve fewer muscular systems, no cognitive effort, and low coordination control effort. We hypothesized it would be unaffected by the dexterity of the volunteers' dominant hand, making it easy to perform using either upper limb, which cannot happen in the case of writing letters or words. 

%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>

More specifically, we investigate the kinematics of hand motion during line drawing task, measuring hand movement at a timescale where there is no conscious control of the motion, so that what we detect is the balance of the tone of agonist versus antagonist muscular systems. This balance is altered in Parkinson's disease and in other pathological conditions. Unlike other studies on the subject, we aimed to make the task as simple as possible for the participants, and thus had them draw simple horizontal lines, hypothesizing that any imbalance in agonist-antagonist coordination should be present even in simple drawings. Our results validate that hypothesis, as we shall see. Furthermore, with lines, participants can draw starting from either side of the writing surface, extending or flexing their arms, allowing us to check the performance of two different groups of muscular systems.
Our hypothesis was that due to impaired coordination in patients with movement disorders, certain features, such as the velocity variability of the pen's tip (to be made precise shortly) or the ``excursions'' from the horizontal, should be more pronounced compared to healthy subjects. Towards that end, our approach involves recording the position of the pen on the tablet and computing a vector of metrics, namely the Normalized Velocity Variability (NVV), the velocity's Standard Deviation (SDV) and Mean (MV), and the signal Entropy (ETP), to characterize the pen's trace spatiotemporally. Using data acquired from healthy and PD individuals, we test the hypothesis that these metrics are statistically different between the two groups. Our hypothesis is based on research proving that velocity- and acceleration-based metrics of voluntary movements can separate pathological from healthy subjects. This includes [11] where PD patients showed a reduced ability to modulate acceleration, leading to smaller than required movements and micrographia, and [20] which showed that that dopamine depletion in PD leads to smaller than normal pallidothalamic gating signals, which in turn affect the ability to control variable movement speed. The variability in handwriting velocity in patients with PD was also noted in [21] where the patients showed multiple peaks in their velocity signal whereas the controls showed just one peak. In [22], the velocity and acceleration profiles of PD patients were different in relation to healthy subjects while writing circles. In a different experimental design investigating the effect of the dopamine on handwriting movements [23], researchers found lower values for maximum and minimum velocity in ascending and descending strokes in PD patients than in healthy subjects. They also found that patients had significantly more inversions of velocity and acceleration than healthy people. There was also a difference between patients on medication and off medication, where the number of inversions in velocity and acceleration was statistically significant. 


We chose to conduct a control study and not a one-population validation study because there was complete lack of literature evidence that this method of collecting inertial signals would work, or even be robust enough for us to gather usable data, and detection of a motor anomaly should be the first step before attempting to evaluate its severity. Our primary goal was to establish whether our tool could identify tremor. In a follow-up clinical trial we would assess its accuracy in quantifying the symptom (see section \ref{sec:SmartCT2}). 

%%%%%%------------> include this!!!!!!!!
%%%%%%------------> include this!!!!!!!!
%%%%%%------------> include this!!!!!!!!
Therefore, the expected outcome of \gls{SmartCT1} was to collect data using a novel tool on a small target population (\gls{SmartPD1}), examine the signals, calculate basic metrics and explore the statistical significance of the metrics when compared to a size-matched control population (\gls{SmartH1}). Most importantly, we wanted to gain significant insight concerning the optimization of the protocol of our next scheduled larger clinical trial (\gls{SmartCT2}).


\subsubsection{Volunteers}
\label{subsubsec:PenCTVolunteers}
Fifty-nine subjects in total participated in this study. All were right-handed, and had normal or corrected-to-normal vision. Their right-handedness was established based on what hand they used to write and eat with, as well as an evaluation of the muscular force of their two hands. The subjects agreed to participate in this study after a detailed explanation of its purposes and procedures. They were divided in three groups based on their health status and age (Table I). 
Group H included 20 healthy persons aged 56-89. All subjects had a detailed neurological examination in order to screen for any movement disorders that would exclude them from the study. None had a first-degree relative with PD or some kind of tremor. Also, none had hypertension or diabetes. Most of the healthy subjects came from retirement facilities.
Group PD had 24 subjects aged 58-80, all under medication. They were recruited from the Parkinson's disease outpatient clinic of the 1st Neurology Department of the Aristotle University of Thessaloniki, Greece. All had been under periodic evaluation and levodopa and/or dopamine agonist treatment for more than a year. Undeniably, patients who are on medication improve on some of their clinical signs and symptoms. Nevertheless, even when a patient is on medication, most PD signs and symptoms never disappear. The symptoms that are mostly alleviated are bradykinesia and rigidity, whereas tremor in most cases is ``drug-resistant'' [24]. Because PD subjects participating in this study were all tested in an outpatient setting, they were kept on medication for ethical and safety reasons (i.e., drug deprivation could lead to injuries). Additionally, most of our patients were not newly-diagnosed (their Hoehn and Yahr rating was above 1) and despite treatment their signs and symptoms were present. Their information is provided in Table II. We introduced a third group of 15 young healthy volunteers (YH) with a mean age 36.40 years. They were included in this study to establish a ``baseline'' for the various metrics, and their scores were compared to those of older healthy volunteers (group H) to test for possible age effects.

\begin{table}[!hp]
\centering
\caption{\textsc{Information on SmartPD2 and SmartPD2L groups}}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}} c c c c c c c}
	\multirow{2}{*}{\textit{Volunteers}} & \multirow{2}{*}{Age} & \multirow{2}{*}{Sex} 
	& \multicolumn{4}{c}{\textit{UPDRS Upper Limb Tremor Items}} \\
	\cline{4-7}
	& & & \textit{Rest Right} & \textit{Rest Left} & \textit{Extended Right} & \textit{Extended Left} \\
	\hline 	\hline 
 	\gls{SmartPD2}$_{1}$ & 76 & F & 0 & 1 & 0 & 1 \\
 	\gls{SmartPD2}$_{2}$ & 77 & M & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{3}$ & 80 & F & 2 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{4}$ & 76 & M & 1 & 0 & 1 & 0 \\
 	\gls{SmartPD2}$_{5}$ & 74 & M & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{6}$ & 76 & M & 0 & 2 & 0 & 0 \\
 	\gls{SmartPD2}$_{7}$ & 62 & F & 0 & 1 & 1 & 1 \\
 	\gls{SmartPD2}$_{8}$ & 82 & M & 0 & 0 & 1 & 1 \\
 	\gls{SmartPD2}$_{9}$ & 69 & F & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{10}$ & 76 & F & 1 & 2 & 1 & 2 \\
 	\gls{SmartPD2}$_{11}$ & 81 & M & 1 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{12}$ & 39 & M & 2 & 1 & 2 & 2 \\
 	\gls{SmartPD2}$_{13}$ & 65 & F & 0 & 2 & 0 & 1 \\
 	\gls{SmartPD2}$_{14}$ & 78 & M & 2 & 0 & 1 & 1\\
 	\gls{SmartPD2}$_{15}$ & 50 & M & 1 & 0 & 0 & 0\\
 	\gls{SmartPD2}$_{16}$ & 75 & F & 0 & 0 & 0 & 1\\
 	\gls{SmartPD2}$_{17}$ & 70 & M & 0 & 0 & 1 & 2 \\
 	\gls{SmartPD2}$_{18}$ & 80 & F & 4 & 4 & 2 & 1 \\
 	\gls{SmartPD2}$_{19}$ & 76 & M & 0 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{20}$ & 75 & F & 2 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{21}$ & 43 & F & 0 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{22}$ & 78 & F & 1 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{23}$ & 73 & F & 0 & 0 & 0 & 0 \\
 	% & & & & & & \\
 	\hline
 	\gls{SmartPD2L}$_{1}$ & 83 & M & 1 & 0 & 0 & 0 \\
 	\gls{SmartPD2L}$_{2}$ & 77 & F & 0 & 1 & 2 & 1 \\
 	& & & & & & \\
	\multicolumn{7}{c}{\gls{UPDRS} scores evaluated during ON state} 	\\
\end{tabular*}
%\label{table:demoSmartPD2}
\end{table}

To complete \gls{SmartCT2PI} we recruited 20 healthy volunteers, \gls{SmartH2}. They were screened for several health conditions which could exclude them from the study, such as hypertension or any movement disorder. They were also notified of the procedure and the purpose of the study before agreeing to participate. Grouping information on all participants of the study is provided in table \ref{table:demoSmartCT2}. 

The volunteers' ages for all the groups were mean-tested with the non-parametric Mann-Whitney U test and were found not to be statistically different at the 1\% significance level, therefore the groups could be considered age-matched.

\begin{table}[!hp]
\centering
\caption{\textsc{Information on Volunteers' Grouping}}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}} c c c c c c }
	\multirow{2}{*}{\textit{Group}} & \multirow{2}{*}{Size}
	& \multicolumn{2}{c}{\textit{Sex Statistics}} & \multicolumn{2}{c}{\textit{Age Statistics}} \\
	\cline{3-6}
	& & \textit{Females} & \textit{Males} & \textit{Mean$\pm$StD} & \textit{SE} \\
	\hline 	\hline 
	\textit{SmartH2} & 20 & 10 & 10 & 67.20$\pm$6.25 & 1.39 \\
	\textit{SmartPD2} & 23 & 12 & 11 & 70.91$\pm$11.78 & 2.45 \\
	\textit{SmartPD2L} & 20 & 10 & 10 & 80.00$\pm$4.24 & 3.00 \\
 	\hline
 	\textit{Total} & 45 & 23 & 22 & & \\
\end{tabular*}
%\label{table:demoSmartCT2}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\



\subsubsection{Procedure and Hardware}
\label{subsubsec:PenCTProcHardware} 
The regimen that had to be followed during all phases of both smartphone-based clinical trials was similar, albeit a few minor modifications after the first trial. As already discussed, the first thing we changed was the size of the groups and distinguishing different phases for each desired output. The hardware used was exactly the same as the one used in \gls{SmartCT1} (see section \ref{subsubsec:smartCT1ProcHardware}). All volunteers had to wear the custom-made glove-case with an iPhone mounted securely on the dorsal part of their hand. However, for all phases of \gls{SmartCT2} we made the following two very important changes:

\begin{enumerate}
\item We added a new posture to assess resting tremor as well as action postural tremor. Since we wanted our metrics and results from \gls{SmartCT2} to be compared with the clinical examination mainstay, the \gls{UPDRS}, we applied the same instructions regarding body posture as described in item 3.15 - Postural tremor of the hands, like we did for \gls{SmartCT1}, and  3.17 - Rest tremor amplitude of the \gls{MDS}-\gls{UPDRS} (Goetz et al, 2008). More specifically, in order to assess postural hand tremor we instructed the volunteers to stretch their arms out in front of the body, keeping their palms facing the ground. The wrists were to be held straight and the fingers separated as to not touch each other, in a comfortable manner. To assess rest tremor we instructed the volunteers to sit comfortably in a chair, with their arms placed on the arms of the chair, without touching their lap, and their feet loosely placed on the floor.
\item We increased the duration of the two postures used to 30 seconds. Unfortunately there was no way to increase the sampling rate of the smartphone's sensors using the DeviceMotion and DeviceOrientation JavaScript interfaces (see section \ref{subsubsec:smartCT1Software}, which was still limited at the marginally acceptable 20Hz threshold. To increase our potential of retrieving valuable information in the collected signals we decided to increase their duration. Increasing the duration of each individual recording, would still keep the total session duration at 240 seconds, i.e., 4 minutes, given that for both postures the device was mounted on both the volunteers' hands alternately, and each recording was repeated twice, resulting in 8 recordings of 30 seconds each.
\end{enumerate}

\noindent
The 23 volunteers of the \gls{SmartPD2} group who underwent the smartphone-based tremor measuring procedure were under medication, but the timespan from their last dose of L-DOPA was anywhere from 1 to 4 hours when they were tested. That means that some of them were at the peak of the drug’s effect while for others this was not the case. For the third phase of the study, \gls{SmartCT2L}, we wanted to see how our tool would perform against an alteration in a patient's condition, such as that brought on by medication intake. The two \gls{SmartPD2L} volunteers stayed in the clinic overnight and followed our experimental protocol both OFF and ON medication, i.e., right before taking their medication in the morning and one hour after that. 

Throughout \gls{SmartCT2}, every time a patient participated in a session, an experienced neurologist would perform a full \gls{UPDRS} examination before the recording. The neurologist was the same for every patient to avoid inter-rater variability. 

As per the \gls{SmartCT1} protocol described earlier, all volunteers were asked to maintain the postures for the defined duration, in the case of \gls{SmartCT2}, 30 seconds, during which the web application running on the glove-case-mounted iPhone automatically collected the accelerometer and gyroscope data and sent them to our server.
 
\subsubsection{Software}
\label{subsubsec:PenCTSoftware}
The software modules used in all phases of \gls{SmartCT2} were to a great extent the same as those used in \gls{SmartCT1}. Apart from collecting signals for a longer period of time, the web application was the same, the Apache server was identical, as was the pipeline executed up to the post processing of the signals. The difference was in the data processing, once the signals were collected, as will be discussed in the following section. When our second trial took place (late 2013 to mid 2014) we actually tested our web application on two Android devices\footnote{A Samsung Galaxy S4 and a Google Nexus 5, both running Android 4.4.2} and it would run successfully. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Collected}
\label{subsec:PenCTData}

As explained earlier, each session consisted of 8 recordings. The volunteers all wore the glove-case on both hands alternately for both postures, measuring rest and postural tremor, repeating twice. The signals were sent directly after each recording to our server where we gathered them and formed each volunteer's acceleration vector, $\alpha(i) = [\alpha_{x}(i),\alpha_{y}(i),\alpha_{z}(i)]^{T}$ (in $m/s^{2}$) and angular velocity, also called rotation rate, vector $\omega(i) = [\omega_{x}(i),\omega_{y}(i),\omega_{z}(i)]^{T}$ (in $rad/s$), with $i$ denoting discrete sample and axes $x$, $y$ and $z$ defined as in figures \ref{fig:iphoneAxes} and \ref{fig:iphoneAxesGyro}. For 30 seconds signals, at 20Hz sampling rate, each session would yield 8 vectors of 600 elements for each axis. For this clinical trial we would also explore the frequency domain of the signals, applying more detailed processing. We applied a band-pass filter with cutoff frequencies of 1.5Hz and 9.5Hz, in order to exclude noise due to breathing, pulse, or any high-frequency sudden movements during the recordings. In figure \ref{fig:accelFFTPD2_3} the spectral analysis through Fast Fourier Transform shows a clear peak in the 4-5Hz range, which is typical frequency for the resting tremor of a \gls{PD} patient (see section \ref{subsec:tremor}). 

To characterize the singals we calculated squared magnitudes combining each sample's axis acceleration (\ref{eq: magSampleAlpha}) and rotation rate (\ref{eq: magSampleOmega}) and summed over all $N$ (600) samples for each signal to calculate $mag_{\alpha}$ (\ref{eq: magAlpha2}) and $mag_{\omega}$ (\ref{eq: magOmega2}).

\noindent
The $sd_{\alpha}$ is the sum of absolute differences in the acceleration vector, summed over each of the three axes, $x$, $y$, and $z$ (\ref{eq: sdAlpha}). To compute the $mAmp_{\omega}$ metric (\ref{eq: maxAmpOmega}) we initially obtained the magnitude of the Fourier transform of each of the three axial components of the rotation vector $\omega(i)$, defined as $\hat{\omega}_{\kappa}(\xi)$, with $\kappa \in \{x,y,z\}$. We then determined each component’s maximum in the $4 \leq \xi \leq 7$Hz range (that range being consistent with the frequency of the majority of Parkinsonian tremor) and summed the three maxima. 

In each session, patients performed two recordings per hand, and each of the metrics (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) was averaged over both trials, giving us an average score for each patient's right hand and another average for their left hand. We kept left and right hand averages distinct, as opposed to averaging all scores for both hands, because \gls{UPDRS} scores are similarly categorized on a left hand and right hand basis. For the following paragraphs we hereby define 4 different aggregation profiles for each of the features calculated from (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}):

\begin{itemize}
\item restR for rest posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.17 right upper extremity (\gls{RUE}) value,
\item restL for rest posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.17 left upper extremity (\gls{LUE}) values,
\item extR for extended hands posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.15 R values, and
\item extL for extended hands posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.15 L values. 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Analysis}
\label{subsec:PenCTAnalysis}
\subsubsection{Means Testing}
\label{subsubsec:PenCTMeansTesting}
Since our goal was to facilitate identification and monitoring of \gls{PD}-induced tremor, it was essential to establish that the metrics calculated from the signals could be relied upon to differentiate the \gls{SmartPD2} and \gls{SmartH2} populations. We used the non-parametric Mann-Whitney U test to explore the statistical significance in the difference of means of the two main populations participating in \gls{SmartCT2}, for all aggregations of the 4 metrics. As shown in table \ref{table:meansTestingSmartCT2}, all between-groups tests found significant differences between the mean scores of the metrics of the \gls{SmartPD2} volunteers compared to the means of the \gls{SmartH2} volunteers, at 1\% significance level.  


This meant that the two populations could be presumed to have significantly different scores for every one of the signal metrics computed, and these metrics could be the basis for differentiation between \gls{SmartPD2} and \gls{SmartH2} volunteers.

As discussed in section \ref{subsec:laterality}, it is typical for \gls{SmartPD2} patients to manifest the disease's symptoms with laterality, i.e., more severely on one side, right or left. Nevertheless, there was no statistically significant difference in the volunteers' left versus right mean metric scores \textit{within} each population. In \gls{SmartCT2}, 19 of the 23 patients have differences between the sums of the \gls{UPDRS} components concerning right versus left hand tremor, indicating laterality of motor impairment. This laterality however, although clinically observable, did not result in the Mann-Whitney U test yielding significant difference regarding the summed \gls{UPDRS} scores for right versus left hands, sustaining the null hypothesis with p = 0.7327, even for the ``gold standard'' \gls{UPDRS} scores. 

In order to identify the laterality statistically, for each metric calculated in (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) we summed the scores of both postures for right and left hand separately and calculated the absolute differences between them. As shown in the last four rows of table \ref{table:meansTestingSmartCT2}, for each metric, the absolute differences between hands for the \gls{SmartPD2} group is statistically different from those of the \gls{SmartH2} group. That means that the magnitude of difference between hands is not the same for \gls{SmartPD2} and \gls{SmartH2}, justifiably attributed to the disease's laterality. 

\subsubsection{Correlation With UPDRS}
\label{subsubsec:PenCTCorrelation}
To establish the validity of our smartphone-based method of upper limb parkinsonian tremor quantification we ran a Pearson product-moment correlation analysis between the \gls{UPDRS} scores of the \gls{SmartPD2} volunteers and their respective signal metrics, to define the correlation coefficients. In our case, each Pearson's correlation coefficient, calculated by (\ref{eq:pearson}), was the fraction of the covariance between a signal metric (each one of (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}), for each one of restR, restL, extR and extL) and its respective \gls{UPDRS} score, as defined in paragraph \ref{subsec:SmartCT2Data}, over the product of their standard deviations. 

\noindent
This fraction, in theory, could take values ranging from $-1$, for total negative linear correlation between the metrics and the \gls{UPDRS} scores, to $+1$ for total positive linear correlation. In (\ref{eq:pearson}), $x_{i}$ abstractly denotes each one of the signal metrics, with $i$ being each patient and $\bar{x}$ the sample mean, and $u_{i}$ denotes the corresponding \gls{UPDRS} score of each patient, with $\bar{u}$ the sample mean.

Table \ref{table:CorrelationSmartPD2} contains the results of the correlation analysis for the rest posture scores (protocol of item 3.17 of the \gls{MDS}-\gls{UPDRS}) and the extended posture scores (protocol of item 3.15 of the \gls{MDS}-\gls{UPDRS}) separately.

In order to analyze the correlation between the \gls{UPDRS} scores of the patients and each of the signal metrics, we computed the Pearson correlation coefficients between the patients' metrics (separately for right versus left hand) and their \gls{UPDRS} scores, for the respective posture and side. We used Pearson product-moment correlation as opposed to concordance correlation coefficients because we were primarily interested in establishing the validity of our smartphone-based method for quantifying hand tremor, by exploring the relationship between the metrics and the scores, and not reproducibility of one same assessment. The coefficients ($r$) and their corresponding p-values are shown in table \ref{table:CorrelationSmartPD2}, with one row devoted to each of the metrics used. We observe that, at a very comfortable confidence level of 1\%, the hypothesis that there is no correlation between the UPDRS scores and the metrics is rejected. The metric showing the highest correlation to the UPDRS scores is rest $sd_{\alpha}$, where the correlation coefficients are 0.77 (right hand) and 0.88 (left hand) with high statistical significance. Given the qualitative and subjective manner in which \gls{UPDRS} scores are assigned by the physicians, a coefficient above 0.7 suggests a strong correlation with our metrics, while p-values less than 1\% indicate a strong statistical significance.

The values in table \ref{table:CorrelationSmartPD2} show that, regarding the rest posture, there was higher correlation between \gls{UPDRS} scores and all the metrics for the patients' left hand, while all patients were right-handed. Regarding the extended posture, there was higher correlation for the patients' right hand, which was the dominant for all of them. This observation could be attributed to chance, however, it could also be related to how the dominant hand could better support the weight of the device while ``controlling'' tremor in their dominant hand while in the rest posture, and how this could not be the case in the more challenging extended posture. Of course to sustain such a claim, further investigation should take place. 

Another thing made obvious by the correlation analysis is the lower correlation shown between the metrics and the scores for the extended posture. Resting tremor seems to be identified and quantified much more consistently than postural tremor with the device mounted on the patients' hand. This could be attributed to the mass and weight of the device, and its effect on the dynamics of the hand and arm system, altering the way postural action tremor manifests. 

Finally, an important fact to take under consideration when analysing the linear correlation between \gls{UPDRS} scores and any automated, sensor-based, amplitude quantification means is that many theories and studies suggest that a 5-point tremor rating scale such as the \gls{UPDRS}, despite its clear instructions of use and precise translation of amplitude cm to points, is ultimately logarithmically related to tremor amplitude. Phychophysics define the relationships between physical stimuli and the perceptions evoked by these stimuli (Gescheider, 1997). In tremor assessment through a \gls{UPDRS} face-to-face examination, the tremor amplitude is the stimuli and the score assigned by the physician is his evoked perception's expression. In (Elble et al, 2006) it is shown that the physician's expression is logarithmically related to the actual stimuli. However, the automated, sensor-based metric is a linear expression of the tremor amplitude. Even for an experienced physician, eager to follow \gls{MDS}' guidelines on using the \gls{UPDRS} scoring, this could largely justify lower than expected linear correlation coefficients between the scores and the automated metrics. 

\subsubsection{Recordings During OFF State}
\label{subsubsec:PenCTOFF}
During \gls{SmartCT2L}, 2 patients, defined as group \gls{SmartPD2L} stayed in the clinic overnight and followed our experimental protocol both during ON and OFF states. In table \ref{table:offSmartCT2} we present the percent differences ON-OFF in the four metrics, along with the \gls{UPDRS} scores for both volunteers. We would expect those differences to be negative because we expect higher metric scores (more pronounced tremor) during the OFF state simulating a de novo state, and lower after the drug ingestion (ON state). 

From the \gls{UPDRS} scores of the two volunteers it is clear that these two patients did not suffer from severe hand tremor. 

Their physician observed that the medication improved mostly the their rigidity, which was not quantified by our tool, and less so their tremor. However, it is encouraging to note that the readings of the smartphone's sensors respond well and follow the expected negative trend of the changes in the \gls{UPDRS} scores during the ON state. The only discrepancy was observed in the extR profile of volunteer \gls{SmartPD2L}$_{2}$ for all metrics, where the $\% \Delta$ was actually positive, however this could be considered circumstantial because for there were no clinical changes in the respective \gls{UPDRS} scores from OFF to ON observed as well. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Supervised Machine Learning To Establish Discriminating Criteria}
\label{subsec:PenCTML}
To ultimately build a practical and ubiquitous tool which would be able to accurately assess upper limb tremor in \gls{PD} patients, it was essential to prove that it could distinguish correctly between healthy vs \gls{PD} signals. In \gls{SmartCT1} we used short signals and simpler metrics, (\ref{eq: magAlpha}), (\ref{eq: magOmega}), but were able to classify accurately 9 out of 10 \gls{PD} volunteers. In this study we recruited a larger group of volunteers, signals of greater duration and four metrics, (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}), which can be used as classification features. 


\subsubsection{Fit of the Metrics as Discriminating Criteria}
\label{subsubsec:PenCTMetricsFit}
In table \ref{table:ROCSmartCT2} we present the results of a receiver operating characteristic (\gls{ROC}) curve fitting analysis between the \gls{SmartH2} and \gls{SmartPD2} groups. For each metric and posture, the percentages of the confusion matrix corresponding to true positive (\gls{TP}) and true negative (\gls{TN}), the area under the curve (\gls{AUC}) value and the cutoff point are shown. The percentages suggest that no one metric or posture alone can be used with confidence as the sole discriminating criterion in the current data set because the highest sensitivity (\gls{TP}) is 87\% and the highest specificity (\gls{TN}) is 95\% but they do not appear concurrently. In fact, the metrics which are based on the gyroscope signal, i.e., $mag_{\omega}$ and $mAmp_{\omega}$, rank higher in combined sensitivity and specificity, whereas the acceleration magnitude ranks high in specificity, which means the acceleration metrics are better at identifying healthy signals. 


\subsubsection{Feature Selection for a Classification Model}
\label{subsubsec:PenCTFeatures}
To investigate our metrics' potential as classifiers on new data, we decided to use a non-parametric decision tree-based ensemble machine learning algorithm for multivariate classification based on the work of (Breiman, 2001), as the authors of (Arora et al, 2014) did. All four metrics (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) for each posture were used, resulting in a set of 16 classification features of a bootstrap aggregation for a random forest of decision trees. We used MATLAB’s \codeword{TreeBagger} class for the construction of the ensemble of trees and its function \codeword{oobPredict} to calculate the trained model's prediction accuracy. The ensemble had 500 grown trees. To overcome the problem of possible over-fitting we used each feature's out-of-bag error estimate, as defined in (Breiman, 2001). That is a measure of importance calculated by the \codeword{TreeBagger} class, defined as the increase in prediction error if the variable's values are permuted across the left out-of-bag observations. The higher the increase, the higher the importance of the given feature (see figure \ref{fig:featuresSmartCT2}). 

We also used three other approaches to evaluate the importance of our model's features, namely Information Gain, One-R and Chi-Squared, as described in (Novakovic, 2010), all tested with 10-fold stratified cross-validation (see table \ref{table:featuresSmartCT2}). For the Information Gain, the One-R and the Chi-Squared approach the merit shown in table \ref{table:featuresSmartCT2} is a correlation-based metric as described in (Hall, 1999). Higher values indicate more important features. 

What we found, after multiple runs with various feature subsets is that the model with the best classification potential, i.e., highest average accuracy and lowest dimensionality, uses the four most important features as calculated by the out-of-bag error and the One-R approach, namely $mAmp_{\omega}$ for aggregation profiles restR, restL and extL, and $mag_{\omega}$ for restL aggregation profiles. The fact that three out of the four most relevant features involve the volunteers' left hand could be related to the fact that all of them were right-handed. Data from left-handed volunteers should also be collected to test whether the dexterity of the dominant hand plays a significant role in that regard.

\subsubsection{The Classification Model}
\label{subsubsec:PenCTClassification}
We used MATLAB's \codeword{TreeBagger} class, which constructs a bagged ensemble of decision trees BagDT, i.e., a Breiman's random forest (Breiman, 2001), to build a classification model that would accurately identify unknown data. Our preference for that approach was guided by its good performance relatively to a total of six machine learning algorithms tested, and whose performance in terms of sensitivity (\gls{TP}), specificity (\gls{TN}) and \gls{AUC} is shown in table \ref{table:MLAlgosSmartCT2}. All classifiers used the same subset of four features deemed to be most important by the feature selection procedure described above. Apart from BagDT, the algorithms were tested with 10-fold stratified cross-validation.
The accuracy of the bagged ensemble of decision trees was better than any of the other classifiers, as it classified correctly 90\% of the \gls{SmartH2} and 82\% of the \gls{SmartPD2} volunteers, with \gls{AUC}$ = 0.9435$ (see figure \ref{fig:ROCSmartCT2}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discussion}
\label{subsec:SmartCT2Discussion}
The purpose of the second smartphone-based study was specifically to validate and improve the results of \gls{SmartCT1}, by:

\begin{itemize}
\item extending the protocol to include rest tremor as well as postural tremor. This was accomplished by adding another position to be assumed by the volunteers, in concordance with item 3.17 of the \gls{MDS}-\gls{UPDRS}, which is used to assess hand rest tremor,
\item recruiting double the number of volunteers,
\item making the inclusion criteria for the healthy volunteers more strict, ultimately populating an age-matched control group,
\item performing simultaneous \gls{UPDRS} assessments to later examine the correlation between the two methods,
\item collecting longer signals using our tool, going from 10 seconds to 30, 
\item calculating more characteristics from the longer signals,
\item simulating de novo patients' examination by recording data from two \gls{PD} volunteers prior to their medication intake,
\item training and testing a machine learning algorithm to explore how our tool would perform when used to classify as healthy or abnormal, new, unlabeled sensor data. 
\end{itemize}

\noindent
Our protocol design changes for \gls{SmartCT2} in comparison to \gls{SmartCT1} proved to be correct. The results from the data analysis showed that our smartphone-based method correlated well with the \gls{UPDRS}, identified changes during ON-OFF fluctuations for the same patient, and could be used to discriminate unlabeled data. 


%%%%%%%%%%%%%%%%%%%% END OF PENCT %%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conclusion and Research Implications}
\label{subsubsec:PenImplications}

Recent advances in mobile phone technology have placed an impressive array of sensing and communication equipment at the hands of an ever-growing number of people, to the point that they can be considered ubiquitous. As discussed in chapter \ref{ch:autoQuant}, researchers have already done much work, exploring the potential of these devices in medical applications. One of the areas which can be transformed by the availability of what is essentially a cheap, ubiquitous networked sensor, is that of remote diagnosis and continuous monitoring of movement disorders, such as \gls{PD}, through the accurate, objective quantification of many of their symptoms. 

Our clinical trial \gls{SmartCT1} proved the concept of a smartphone-based method for detecting and quantifying the hand tremor associated with movement disorders using signals from the accelerometer and gyroscope embedded in the patient's phone. Our approach was web-based and user-friendly, requiring minimal user interaction. By recruiting twenty subjects divided in two groups, \gls{SmartPD1} consisting of 10 \gls{PD} patients and \gls{SmartH1} consisting of 10 healthy controls, we found that by combining both accelerometer and gyroscope signals, we were able to correctly identify those suffering from hand tremor, using very simple signal metrics ((\ref{eq: magAlpha}), (\ref{eq: magOmega})). 

More specifically, we explored the use of recently-available smartphone technology and JavaScript \gls{API}s for the purpose of quantifying and diagnosing the upper limb postural tremor which is a dominant symptom in \gls{PD}. Our method was based on the use of on-board accelerometer and gyroscope and collect their signals through a web application. Unlike previously proposed approaches (see section \ref{subsec:smartphones}), ours i) was web-based, meaning that the user would simply have to visit a web page without installing software on their phone, or handling the data being collected, and ii) used accelerometer and gyroscope data simultaneously in order to classify patients based on very simple signal metrics and thresholding. The analysis that followed \gls{SmartCT1} showed that by using simple signal processing we could correctly categorize nine of the ten patients, based on the power of their acceleration and rotational velocity signals, or the differences in performance between their two hands. The gyroscope data appeared to be particularly useful in that regard. The results were published in (Kostikis et al, 2011). 

What \gls{SmartCT1} showed was that a smartphone has the potential to be used in a clinical setting, to quantify human upper limb tremor and identify pathological abnormalities. A larger clinical trial was conducted later to validate the approach and further establish each value. \gls{SmartCT2} was designed to offer longer signals from double the number of participants, with simultaneous \gls{UPDRS} logging from the same exert neurologist, to avoid inter-rater variability. Upon completion of the study, the first test we conducted was that of the correlation between our method of evaluating tremor and the ``gold standard'' of the clinical examination, the \gls{UPDRS} ratings (Kostikis et al, 2014). Even though most physicians' scores when using the \gls{UPDRS} follow a logarithmic pattern when compared to the actual tremor amplitude (see section \ref{subsubsec:SmartCT2Correlation}), the results were promising, particularly regarding the resting tremor testing protocol (following the directions for rating \gls{MDS}-\gls{UPDRS} item 3.17), with Pearson correlation coefficient values in the range of $0.69 - 0.88$, with nearly zero $p$ values. Although we do not advocate the replacement of the \gls{UPDRS} clinical test, we were interested in using the sensors of a ubiquitous device to assist the physician, providing him with an objective method to quantify resting hand tremor efficiently, accurately and remotely. 

By further analyzing the data collected from \gls{SmartCT2} we were able to propose a method to quantify \gls{PD} induced hand tremor. We incorporated an ensemble of decision trees as a machine learning model and we were able to positively identify 82\% of our \gls{PD} volunteers and 90\% of the healthy volunteers (Kostikis et al, 2015). Although both our clinical trials were relatively small, they served as proof of concept and offered encouraging results. The statistical analyses we conducted showed that our proposed method could be used both in a clinical setting to facilitate the physician's work by offering an accurate assessment tool, and at home by the patients themselves to self-monitor their progress. 

The availability of such a ubiquitous assessment tool of an otherwise subjectively rated symptom, such as hand tremor, primarily assists the physician in planning an effective treatment regimen. However, the ability to easily measure hand tremor daily at home by means of the method proposed and storing the relevant metrics in order to later track and visualize the progression of the disease and the effectiveness of the medication is more than welcome as a benefit for the patient himself. Finally, biobanking large data sets with motor information collected according to a specific protocol is something the scientific community could harvest and conduct valuable research on. Our motion monitoring apparatus, combined with signal processing and machine learning could detect motor abnormalities in a non-invasive manner and assist in the diagnosis and long-term improvement of quality of life for PD patients. 
