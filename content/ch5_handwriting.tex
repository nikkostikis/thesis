\chapter{Parkinson's Symptom Quantification via Simple Drawing and Handwriting Markers}
\label{ch:handwriting}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[OC]{\leftmark}
\fancyhead[EC]{\rightmark}
\cfoot{\thepage}


%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{General Approach}
\label{sec:PenGenApproach}
As discussed in section \ref{sec:handwriting}, handwriting-related tasks have been proven to work reasonably well in identifying and quantifying abnormal patterns in \gls{PD} patients. There are two phenomena defined and related with \gls{PD} pathology:

\begin{itemize}
\item Micrographia, which entails the reduction in size of the lettering of the writer in comparison with his writing style before the disease onset (Wilson, 1925). There are two types, the consistent micrographia, where there is a global reduction in lettering size, and the progressive, where the writer gradually produces smaller letters after writing a few characters. Micrographia has not been found to be directly related to any other particular \gls{PD} symptom. The consistent type is responsive to levodopa, whereas the progressive one is medication resistant. 
\item Dysgraphia, which includes any abnormal behavior in the mechanics of handwriting skills (Letanneux et al, 2014). Researchers believe that all motor impairments of \gls{PD}, such as the \gls{TRAP} complex, reduced visuospatial perception, and motor coordination deficiencies can actually contribute to pathological handwriting kinematics, in combination with and beyond writing size. 
\end{itemize}



The dysgraphia ``umbrella'' term implies that the same motor impairments may be present and detectable through simple handwriting tasks, even when micrographia is not detectable. 

Dysgraphia assessment would entail various and more sophisticated features being extracted from even simple drawing movements, and signal analysis going beyond stroke size and duration to identify discriminating characteristics and reveal early and subtle impairments.

Our approach was based on the following pillars: 

\begin{enumerate}
\item We focused on exploring the use of a ubiquitous device, such as a smartphone, with no additional software installed apart from its factory-installed operating system, and without the need to attach external hardware on it. 
\item We avoided making assumptions about the users, i.e. that they would have e-mail accounts or that they would be proficient enough to install and manage applications and configure complex settings. 
\item We explored solutions that would not require the presence of an expert to use, but would still produce replicable and accurate symptoms quantification. 
\item We opted for cloud based approaches that would ensure the persistence of the data and the availability of the results for post-processing and verification. 
\end{enumerate}

\noindent
To validate our symptoms quantification approach we conducted two separate clinical trials: 

\begin{enumerate}
\item The first was a small-scale case control pilot clinical trial (\gls{SmartCT1}), which would serve as proof-of-concept for our approach (Kostikis et al, 2011). It consisted of 10 patients with idiopathic \gls{PD}, defined as group \gls{SmartPD1}, and 10 age-matched healthy volunteers, defined as group \gls{SmartH1}. The data collected were post-processed using signal processing and statistically analyzed, to calculate quantifying metrics and establish their significance. 
\item The second was a larger case control clinical trial (\gls{SmartCT2}), were 23 patients with idiopathic \gls{PD}, defined as group \gls{SmartPD2}, and 20 age-matched healthy volunteers, defined as group \gls{SmartH2}, were recruited. In a preliminary validation study, we used the data collected from \gls{SmartPD2} to compare the quantification calculated by our tool, to the patients' \gls{UPDRS} scores (Kostikis et al, 2014). Later on, both the \gls{SmartPD2} and \gls{SmartH2} groups' data were processed and used to perform statistical analysis and build machine learning models to establish our tool's potential as a classification platform for \gls{PD} patients (Kostikis et al, 2015). During the second clinical trial we also conducted a small longitudinal trial (\gls{SmartCT2L}) recruiting two idiopathic \gls{PD} patients, defined as \gls{SmartPD2L}. They were inpatients and were screened with our tool twice, once before, and once after medication. 
\end{enumerate}

In the following section we will describe the smartphone-based clinical trials we conducted, present the data processing pipeline applied in each trial and discuss the results obtained in each case, and the implications derived from our smartphone-based \gls{PD} symptoms quantification approach. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PenCT}
\label{sec:PenCT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Protocol}
\label{subsec:PenCTProtocol}

\subsubsection{Rationale}
\label{subsubsec:PenCTRationale}
Two valuable conclusions were drawn from the \gls{SmartCT1} results:

\begin{enumerate}
\item Our web-based tool could be used as a complement to the current clinical mainstay to evaluate tremor.
\item Improvements would have to be made wherever possible to eliminate the shortcomings of the previous protocol and make our solution more robust and valuable as a tremor quantification tool. 
\end{enumerate}

The second conclusion drove us to our second clinical trial, \gls{SmartCT2}. We designed \gls{SmartCT2} having validation in mind. In order to validate our tool it would be necessary to compare it to results from \gls{UPDRS} assessments conducted at the same time of the recording sessions. To that end we designed three separate phases within the trial:

\begin{itemize}
\item In phase I (\gls{SmartCT2PI}) we collected signals from patients with parkinsonism manifestations, which we used to run correlation analysis, using their \gls{UPDRS} scores as input. In order for our tool to be validated as a tremor quantification approach it should prove to perform at least as well as the ``gold standard'' of \gls{PD} clinical examination, the \gls{UPDRS}. The new group of patients, \gls{SmartPD2} was recruited to be assessed both using the \gls{UPDRS} and our web-based smartphone tool. A correlation analysis was conducted to reveal whether the two methods produce similar results. \gls{SmartCT2PI} alone was actually a one population validation study. 
\item In phase II (\gls{SmartCT2PII}) we collected signals from a control group with strict inclusion criteria to pursuit the creation of a classification machine-learning model. The new control group, \gls{SmartH2} was recruited to be used as the alternative class compared to the patients. Both groups' performances calculated with our tool were used to train a supervised machine-learning algorithm to identify the class of new unlabeled signals. 
\item In phase III - longitudinal (\gls{SmartCT2L}) we conducted a small longitudinal study to further evaluate our tool's performance in identifying changes in a single patient's symptom severity over time. This phase's group, \gls{SmartPD2L} participated in recording sessions during both the ON and OFF state (see section \ref{sec:dyskinesia}), to explore our tool's capacity in identifying same-patient fluctuations in tremor.
\end{itemize}

\subsubsection{Volunteers}
\label{subsubsec:PenCTVolunteers}
To conduct \gls{SmartCT2PI} we recruited 23 \gls{PD} patients, \gls{SmartPD2}, from the outpatient clinic of the 1st Department of Neurology of AHEPA University General Hospital, located in the territory of the Aristotle University of Thessaloniki. All subjects agreed to participate in this research after a detailed explanation of its aims and of the testing procedure. All \gls{SmartPD2} volunteers were right-handed, under L-DOPA treatment and suffering from \gls{PD} for more than two years.
For the \gls{SmartCT2L} phase we recruited two \gls{PD} patients, \gls{SmartPD2L} who were hospitalized overnight in the AHEPA University General Hospital, so that they could be recorded in the morning before they received their medication, aiming to capture their OFF state. Table \ref{table:demoSmartPD2} summarizes information on the patients participating in \gls{SmartCT2}. 

\begin{table}[!hp]
\centering
\caption{\textsc{Information on SmartPD2 and SmartPD2L groups}}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}} c c c c c c c}
	\multirow{2}{*}{\textit{Volunteers}} & \multirow{2}{*}{Age} & \multirow{2}{*}{Sex} 
	& \multicolumn{4}{c}{\textit{UPDRS Upper Limb Tremor Items}} \\
	\cline{4-7}
	& & & \textit{Rest Right} & \textit{Rest Left} & \textit{Extended Right} & \textit{Extended Left} \\
	\hline 	\hline 
 	\gls{SmartPD2}$_{1}$ & 76 & F & 0 & 1 & 0 & 1 \\
 	\gls{SmartPD2}$_{2}$ & 77 & M & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{3}$ & 80 & F & 2 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{4}$ & 76 & M & 1 & 0 & 1 & 0 \\
 	\gls{SmartPD2}$_{5}$ & 74 & M & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{6}$ & 76 & M & 0 & 2 & 0 & 0 \\
 	\gls{SmartPD2}$_{7}$ & 62 & F & 0 & 1 & 1 & 1 \\
 	\gls{SmartPD2}$_{8}$ & 82 & M & 0 & 0 & 1 & 1 \\
 	\gls{SmartPD2}$_{9}$ & 69 & F & 0 & 0 & 0 & 1 \\
 	\gls{SmartPD2}$_{10}$ & 76 & F & 1 & 2 & 1 & 2 \\
 	\gls{SmartPD2}$_{11}$ & 81 & M & 1 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{12}$ & 39 & M & 2 & 1 & 2 & 2 \\
 	\gls{SmartPD2}$_{13}$ & 65 & F & 0 & 2 & 0 & 1 \\
 	\gls{SmartPD2}$_{14}$ & 78 & M & 2 & 0 & 1 & 1\\
 	\gls{SmartPD2}$_{15}$ & 50 & M & 1 & 0 & 0 & 0\\
 	\gls{SmartPD2}$_{16}$ & 75 & F & 0 & 0 & 0 & 1\\
 	\gls{SmartPD2}$_{17}$ & 70 & M & 0 & 0 & 1 & 2 \\
 	\gls{SmartPD2}$_{18}$ & 80 & F & 4 & 4 & 2 & 1 \\
 	\gls{SmartPD2}$_{19}$ & 76 & M & 0 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{20}$ & 75 & F & 2 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{21}$ & 43 & F & 0 & 0 & 0 & 0 \\
 	\gls{SmartPD2}$_{22}$ & 78 & F & 1 & 0 & 2 & 1 \\
 	\gls{SmartPD2}$_{23}$ & 73 & F & 0 & 0 & 0 & 0 \\
 	% & & & & & & \\
 	\hline
 	\gls{SmartPD2L}$_{1}$ & 83 & M & 1 & 0 & 0 & 0 \\
 	\gls{SmartPD2L}$_{2}$ & 77 & F & 0 & 1 & 2 & 1 \\
 	& & & & & & \\
	\multicolumn{7}{c}{\gls{UPDRS} scores evaluated during ON state} 	\\
\end{tabular*}
%\label{table:demoSmartPD2}
\end{table}

To complete \gls{SmartCT2PI} we recruited 20 healthy volunteers, \gls{SmartH2}. They were screened for several health conditions which could exclude them from the study, such as hypertension or any movement disorder. They were also notified of the procedure and the purpose of the study before agreeing to participate. Grouping information on all participants of the study is provided in table \ref{table:demoSmartCT2}. 

The volunteers' ages for all the groups were mean-tested with the non-parametric Mann-Whitney U test and were found not to be statistically different at the 1\% significance level, therefore the groups could be considered age-matched.

\begin{table}[!hp]
\centering
\caption{\textsc{Information on Volunteers' Grouping}}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}} c c c c c c }
	\multirow{2}{*}{\textit{Group}} & \multirow{2}{*}{Size}
	& \multicolumn{2}{c}{\textit{Sex Statistics}} & \multicolumn{2}{c}{\textit{Age Statistics}} \\
	\cline{3-6}
	& & \textit{Females} & \textit{Males} & \textit{Mean$\pm$StD} & \textit{SE} \\
	\hline 	\hline 
	\textit{SmartH2} & 20 & 10 & 10 & 67.20$\pm$6.25 & 1.39 \\
	\textit{SmartPD2} & 23 & 12 & 11 & 70.91$\pm$11.78 & 2.45 \\
	\textit{SmartPD2L} & 20 & 10 & 10 & 80.00$\pm$4.24 & 3.00 \\
 	\hline
 	\textit{Total} & 45 & 23 & 22 & & \\
\end{tabular*}
%\label{table:demoSmartCT2}
\end{table}

\subsubsection{Procedure and Hardware}
\label{subsubsec:PenCTProcHardware} 
The regimen that had to be followed during all phases of both smartphone-based clinical trials was similar, albeit a few minor modifications after the first trial. As already discussed, the first thing we changed was the size of the groups and distinguishing different phases for each desired output. The hardware used was exactly the same as the one used in \gls{SmartCT1} (see section \ref{subsubsec:smartCT1ProcHardware}). All volunteers had to wear the custom-made glove-case with an iPhone mounted securely on the dorsal part of their hand. However, for all phases of \gls{SmartCT2} we made the following two very important changes:

\begin{enumerate}
\item We added a new posture to assess resting tremor as well as action postural tremor. Since we wanted our metrics and results from \gls{SmartCT2} to be compared with the clinical examination mainstay, the \gls{UPDRS}, we applied the same instructions regarding body posture as described in item 3.15 - Postural tremor of the hands, like we did for \gls{SmartCT1}, and  3.17 - Rest tremor amplitude of the \gls{MDS}-\gls{UPDRS} (Goetz et al, 2008). More specifically, in order to assess postural hand tremor we instructed the volunteers to stretch their arms out in front of the body, keeping their palms facing the ground. The wrists were to be held straight and the fingers separated as to not touch each other, in a comfortable manner. To assess rest tremor we instructed the volunteers to sit comfortably in a chair, with their arms placed on the arms of the chair, without touching their lap, and their feet loosely placed on the floor.
\item We increased the duration of the two postures used to 30 seconds. Unfortunately there was no way to increase the sampling rate of the smartphone's sensors using the DeviceMotion and DeviceOrientation JavaScript interfaces (see section \ref{subsubsec:smartCT1Software}, which was still limited at the marginally acceptable 20Hz threshold. To increase our potential of retrieving valuable information in the collected signals we decided to increase their duration. Increasing the duration of each individual recording, would still keep the total session duration at 240 seconds, i.e., 4 minutes, given that for both postures the device was mounted on both the volunteers' hands alternately, and each recording was repeated twice, resulting in 8 recordings of 30 seconds each.
\end{enumerate}

\noindent
The 23 volunteers of the \gls{SmartPD2} group who underwent the smartphone-based tremor measuring procedure were under medication, but the timespan from their last dose of L-DOPA was anywhere from 1 to 4 hours when they were tested. That means that some of them were at the peak of the drug’s effect while for others this was not the case. For the third phase of the study, \gls{SmartCT2L}, we wanted to see how our tool would perform against an alteration in a patient's condition, such as that brought on by medication intake. The two \gls{SmartPD2L} volunteers stayed in the clinic overnight and followed our experimental protocol both OFF and ON medication, i.e., right before taking their medication in the morning and one hour after that. 

Throughout \gls{SmartCT2}, every time a patient participated in a session, an experienced neurologist would perform a full \gls{UPDRS} examination before the recording. The neurologist was the same for every patient to avoid inter-rater variability. 

As per the \gls{SmartCT1} protocol described earlier, all volunteers were asked to maintain the postures for the defined duration, in the case of \gls{SmartCT2}, 30 seconds, during which the web application running on the glove-case-mounted iPhone automatically collected the accelerometer and gyroscope data and sent them to our server.
 
\subsubsection{Software}
\label{subsubsec:PenCTSoftware}
The software modules used in all phases of \gls{SmartCT2} were to a great extent the same as those used in \gls{SmartCT1}. Apart from collecting signals for a longer period of time, the web application was the same, the Apache server was identical, as was the pipeline executed up to the post processing of the signals. The difference was in the data processing, once the signals were collected, as will be discussed in the following section. When our second trial took place (late 2013 to mid 2014) we actually tested our web application on two Android devices\footnote{A Samsung Galaxy S4 and a Google Nexus 5, both running Android 4.4.2} and it would run successfully. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Collected}
\label{subsec:PenCTData}

As explained earlier, each session consisted of 8 recordings. The volunteers all wore the glove-case on both hands alternately for both postures, measuring rest and postural tremor, repeating twice. The signals were sent directly after each recording to our server where we gathered them and formed each volunteer's acceleration vector, $\alpha(i) = [\alpha_{x}(i),\alpha_{y}(i),\alpha_{z}(i)]^{T}$ (in $m/s^{2}$) and angular velocity, also called rotation rate, vector $\omega(i) = [\omega_{x}(i),\omega_{y}(i),\omega_{z}(i)]^{T}$ (in $rad/s$), with $i$ denoting discrete sample and axes $x$, $y$ and $z$ defined as in figures \ref{fig:iphoneAxes} and \ref{fig:iphoneAxesGyro}. For 30 seconds signals, at 20Hz sampling rate, each session would yield 8 vectors of 600 elements for each axis. For this clinical trial we would also explore the frequency domain of the signals, applying more detailed processing. We applied a band-pass filter with cutoff frequencies of 1.5Hz and 9.5Hz, in order to exclude noise due to breathing, pulse, or any high-frequency sudden movements during the recordings. In figure \ref{fig:accelFFTPD2_3} the spectral analysis through Fast Fourier Transform shows a clear peak in the 4-5Hz range, which is typical frequency for the resting tremor of a \gls{PD} patient (see section \ref{subsec:tremor}). 

To characterize the singals we calculated squared magnitudes combining each sample's axis acceleration (\ref{eq: magSampleAlpha}) and rotation rate (\ref{eq: magSampleOmega}) and summed over all $N$ (600) samples for each signal to calculate $mag_{\alpha}$ (\ref{eq: magAlpha2}) and $mag_{\omega}$ (\ref{eq: magOmega2}).

\noindent
The $sd_{\alpha}$ is the sum of absolute differences in the acceleration vector, summed over each of the three axes, $x$, $y$, and $z$ (\ref{eq: sdAlpha}). To compute the $mAmp_{\omega}$ metric (\ref{eq: maxAmpOmega}) we initially obtained the magnitude of the Fourier transform of each of the three axial components of the rotation vector $\omega(i)$, defined as $\hat{\omega}_{\kappa}(\xi)$, with $\kappa \in \{x,y,z\}$. We then determined each component’s maximum in the $4 \leq \xi \leq 7$Hz range (that range being consistent with the frequency of the majority of Parkinsonian tremor) and summed the three maxima. 

In each session, patients performed two recordings per hand, and each of the metrics (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) was averaged over both trials, giving us an average score for each patient's right hand and another average for their left hand. We kept left and right hand averages distinct, as opposed to averaging all scores for both hands, because \gls{UPDRS} scores are similarly categorized on a left hand and right hand basis. For the following paragraphs we hereby define 4 different aggregation profiles for each of the features calculated from (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}):

\begin{itemize}
\item restR for rest posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.17 right upper extremity (\gls{RUE}) value,
\item restL for rest posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.17 left upper extremity (\gls{LUE}) values,
\item extR for extended hands posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.15 R values, and
\item extL for extended hands posture, corresponding to the \gls{MDS}-\gls{UPDRS} item 3.15 L values. 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Analysis}
\label{subsec:PenCTAnalysis}
\subsubsection{Means Testing}
\label{subsubsec:PenCTMeansTesting}
Since our goal was to facilitate identification and monitoring of \gls{PD}-induced tremor, it was essential to establish that the metrics calculated from the signals could be relied upon to differentiate the \gls{SmartPD2} and \gls{SmartH2} populations. We used the non-parametric Mann-Whitney U test to explore the statistical significance in the difference of means of the two main populations participating in \gls{SmartCT2}, for all aggregations of the 4 metrics. As shown in table \ref{table:meansTestingSmartCT2}, all between-groups tests found significant differences between the mean scores of the metrics of the \gls{SmartPD2} volunteers compared to the means of the \gls{SmartH2} volunteers, at 1\% significance level.  


This meant that the two populations could be presumed to have significantly different scores for every one of the signal metrics computed, and these metrics could be the basis for differentiation between \gls{SmartPD2} and \gls{SmartH2} volunteers.

As discussed in section \ref{subsec:laterality}, it is typical for \gls{SmartPD2} patients to manifest the disease's symptoms with laterality, i.e., more severely on one side, right or left. Nevertheless, there was no statistically significant difference in the volunteers' left versus right mean metric scores \textit{within} each population. In \gls{SmartCT2}, 19 of the 23 patients have differences between the sums of the \gls{UPDRS} components concerning right versus left hand tremor, indicating laterality of motor impairment. This laterality however, although clinically observable, did not result in the Mann-Whitney U test yielding significant difference regarding the summed \gls{UPDRS} scores for right versus left hands, sustaining the null hypothesis with p = 0.7327, even for the ``gold standard'' \gls{UPDRS} scores. 

In order to identify the laterality statistically, for each metric calculated in (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) we summed the scores of both postures for right and left hand separately and calculated the absolute differences between them. As shown in the last four rows of table \ref{table:meansTestingSmartCT2}, for each metric, the absolute differences between hands for the \gls{SmartPD2} group is statistically different from those of the \gls{SmartH2} group. That means that the magnitude of difference between hands is not the same for \gls{SmartPD2} and \gls{SmartH2}, justifiably attributed to the disease's laterality. 

\subsubsection{Correlation With UPDRS}
\label{subsubsec:PenCTCorrelation}
To establish the validity of our smartphone-based method of upper limb parkinsonian tremor quantification we ran a Pearson product-moment correlation analysis between the \gls{UPDRS} scores of the \gls{SmartPD2} volunteers and their respective signal metrics, to define the correlation coefficients. In our case, each Pearson's correlation coefficient, calculated by (\ref{eq:pearson}), was the fraction of the covariance between a signal metric (each one of (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}), for each one of restR, restL, extR and extL) and its respective \gls{UPDRS} score, as defined in paragraph \ref{subsec:SmartCT2Data}, over the product of their standard deviations. 

\noindent
This fraction, in theory, could take values ranging from $-1$, for total negative linear correlation between the metrics and the \gls{UPDRS} scores, to $+1$ for total positive linear correlation. In (\ref{eq:pearson}), $x_{i}$ abstractly denotes each one of the signal metrics, with $i$ being each patient and $\bar{x}$ the sample mean, and $u_{i}$ denotes the corresponding \gls{UPDRS} score of each patient, with $\bar{u}$ the sample mean.

Table \ref{table:CorrelationSmartPD2} contains the results of the correlation analysis for the rest posture scores (protocol of item 3.17 of the \gls{MDS}-\gls{UPDRS}) and the extended posture scores (protocol of item 3.15 of the \gls{MDS}-\gls{UPDRS}) separately.

In order to analyze the correlation between the \gls{UPDRS} scores of the patients and each of the signal metrics, we computed the Pearson correlation coefficients between the patients' metrics (separately for right versus left hand) and their \gls{UPDRS} scores, for the respective posture and side. We used Pearson product-moment correlation as opposed to concordance correlation coefficients because we were primarily interested in establishing the validity of our smartphone-based method for quantifying hand tremor, by exploring the relationship between the metrics and the scores, and not reproducibility of one same assessment. The coefficients ($r$) and their corresponding p-values are shown in table \ref{table:CorrelationSmartPD2}, with one row devoted to each of the metrics used. We observe that, at a very comfortable confidence level of 1\%, the hypothesis that there is no correlation between the UPDRS scores and the metrics is rejected. The metric showing the highest correlation to the UPDRS scores is rest $sd_{\alpha}$, where the correlation coefficients are 0.77 (right hand) and 0.88 (left hand) with high statistical significance. Given the qualitative and subjective manner in which \gls{UPDRS} scores are assigned by the physicians, a coefficient above 0.7 suggests a strong correlation with our metrics, while p-values less than 1\% indicate a strong statistical significance.

The values in table \ref{table:CorrelationSmartPD2} show that, regarding the rest posture, there was higher correlation between \gls{UPDRS} scores and all the metrics for the patients' left hand, while all patients were right-handed. Regarding the extended posture, there was higher correlation for the patients' right hand, which was the dominant for all of them. This observation could be attributed to chance, however, it could also be related to how the dominant hand could better support the weight of the device while ``controlling'' tremor in their dominant hand while in the rest posture, and how this could not be the case in the more challenging extended posture. Of course to sustain such a claim, further investigation should take place. 

Another thing made obvious by the correlation analysis is the lower correlation shown between the metrics and the scores for the extended posture. Resting tremor seems to be identified and quantified much more consistently than postural tremor with the device mounted on the patients' hand. This could be attributed to the mass and weight of the device, and its effect on the dynamics of the hand and arm system, altering the way postural action tremor manifests. 

Finally, an important fact to take under consideration when analysing the linear correlation between \gls{UPDRS} scores and any automated, sensor-based, amplitude quantification means is that many theories and studies suggest that a 5-point tremor rating scale such as the \gls{UPDRS}, despite its clear instructions of use and precise translation of amplitude cm to points, is ultimately logarithmically related to tremor amplitude. Phychophysics define the relationships between physical stimuli and the perceptions evoked by these stimuli (Gescheider, 1997). In tremor assessment through a \gls{UPDRS} face-to-face examination, the tremor amplitude is the stimuli and the score assigned by the physician is his evoked perception's expression. In (Elble et al, 2006) it is shown that the physician's expression is logarithmically related to the actual stimuli. However, the automated, sensor-based metric is a linear expression of the tremor amplitude. Even for an experienced physician, eager to follow \gls{MDS}' guidelines on using the \gls{UPDRS} scoring, this could largely justify lower than expected linear correlation coefficients between the scores and the automated metrics. 

\subsubsection{Recordings During OFF State}
\label{subsubsec:PenCTOFF}
During \gls{SmartCT2L}, 2 patients, defined as group \gls{SmartPD2L} stayed in the clinic overnight and followed our experimental protocol both during ON and OFF states. In table \ref{table:offSmartCT2} we present the percent differences ON-OFF in the four metrics, along with the \gls{UPDRS} scores for both volunteers. We would expect those differences to be negative because we expect higher metric scores (more pronounced tremor) during the OFF state simulating a de novo state, and lower after the drug ingestion (ON state). 

From the \gls{UPDRS} scores of the two volunteers it is clear that these two patients did not suffer from severe hand tremor. 

Their physician observed that the medication improved mostly the their rigidity, which was not quantified by our tool, and less so their tremor. However, it is encouraging to note that the readings of the smartphone's sensors respond well and follow the expected negative trend of the changes in the \gls{UPDRS} scores during the ON state. The only discrepancy was observed in the extR profile of volunteer \gls{SmartPD2L}$_{2}$ for all metrics, where the $\% \Delta$ was actually positive, however this could be considered circumstantial because for there were no clinical changes in the respective \gls{UPDRS} scores from OFF to ON observed as well. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Supervised Machine Learning To Establish Discriminating Criteria}
\label{subsec:PenCTML}
To ultimately build a practical and ubiquitous tool which would be able to accurately assess upper limb tremor in \gls{PD} patients, it was essential to prove that it could distinguish correctly between healthy vs \gls{PD} signals. In \gls{SmartCT1} we used short signals and simpler metrics, (\ref{eq: magAlpha}), (\ref{eq: magOmega}), but were able to classify accurately 9 out of 10 \gls{PD} volunteers. In this study we recruited a larger group of volunteers, signals of greater duration and four metrics, (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}), which can be used as classification features. 


\subsubsection{Fit of the Metrics as Discriminating Criteria}
\label{subsubsec:PenCTMetricsFit}
In table \ref{table:ROCSmartCT2} we present the results of a receiver operating characteristic (\gls{ROC}) curve fitting analysis between the \gls{SmartH2} and \gls{SmartPD2} groups. For each metric and posture, the percentages of the confusion matrix corresponding to true positive (\gls{TP}) and true negative (\gls{TN}), the area under the curve (\gls{AUC}) value and the cutoff point are shown. The percentages suggest that no one metric or posture alone can be used with confidence as the sole discriminating criterion in the current data set because the highest sensitivity (\gls{TP}) is 87\% and the highest specificity (\gls{TN}) is 95\% but they do not appear concurrently. In fact, the metrics which are based on the gyroscope signal, i.e., $mag_{\omega}$ and $mAmp_{\omega}$, rank higher in combined sensitivity and specificity, whereas the acceleration magnitude ranks high in specificity, which means the acceleration metrics are better at identifying healthy signals. 


\subsubsection{Feature Selection for a Classification Model}
\label{subsubsec:PenCTFeatures}
To investigate our metrics' potential as classifiers on new data, we decided to use a non-parametric decision tree-based ensemble machine learning algorithm for multivariate classification based on the work of (Breiman, 2001), as the authors of (Arora et al, 2014) did. All four metrics (\ref{eq: magAlpha2})-(\ref{eq: maxAmpOmega}) for each posture were used, resulting in a set of 16 classification features of a bootstrap aggregation for a random forest of decision trees. We used MATLAB’s \codeword{TreeBagger} class for the construction of the ensemble of trees and its function \codeword{oobPredict} to calculate the trained model's prediction accuracy. The ensemble had 500 grown trees. To overcome the problem of possible over-fitting we used each feature's out-of-bag error estimate, as defined in (Breiman, 2001). That is a measure of importance calculated by the \codeword{TreeBagger} class, defined as the increase in prediction error if the variable's values are permuted across the left out-of-bag observations. The higher the increase, the higher the importance of the given feature (see figure \ref{fig:featuresSmartCT2}). 

We also used three other approaches to evaluate the importance of our model's features, namely Information Gain, One-R and Chi-Squared, as described in (Novakovic, 2010), all tested with 10-fold stratified cross-validation (see table \ref{table:featuresSmartCT2}). For the Information Gain, the One-R and the Chi-Squared approach the merit shown in table \ref{table:featuresSmartCT2} is a correlation-based metric as described in (Hall, 1999). Higher values indicate more important features. 

What we found, after multiple runs with various feature subsets is that the model with the best classification potential, i.e., highest average accuracy and lowest dimensionality, uses the four most important features as calculated by the out-of-bag error and the One-R approach, namely $mAmp_{\omega}$ for aggregation profiles restR, restL and extL, and $mag_{\omega}$ for restL aggregation profiles. The fact that three out of the four most relevant features involve the volunteers' left hand could be related to the fact that all of them were right-handed. Data from left-handed volunteers should also be collected to test whether the dexterity of the dominant hand plays a significant role in that regard.

\subsubsection{The Classification Model}
\label{subsubsec:PenCTClassification}
We used MATLAB's \codeword{TreeBagger} class, which constructs a bagged ensemble of decision trees BagDT, i.e., a Breiman's random forest (Breiman, 2001), to build a classification model that would accurately identify unknown data. Our preference for that approach was guided by its good performance relatively to a total of six machine learning algorithms tested, and whose performance in terms of sensitivity (\gls{TP}), specificity (\gls{TN}) and \gls{AUC} is shown in table \ref{table:MLAlgosSmartCT2}. All classifiers used the same subset of four features deemed to be most important by the feature selection procedure described above. Apart from BagDT, the algorithms were tested with 10-fold stratified cross-validation.
The accuracy of the bagged ensemble of decision trees was better than any of the other classifiers, as it classified correctly 90\% of the \gls{SmartH2} and 82\% of the \gls{SmartPD2} volunteers, with \gls{AUC}$ = 0.9435$ (see figure \ref{fig:ROCSmartCT2}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discussion}
\label{subsec:SmartCT2Discussion}
The purpose of the second smartphone-based study was specifically to validate and improve the results of \gls{SmartCT1}, by:

\begin{itemize}
\item extending the protocol to include rest tremor as well as postural tremor. This was accomplished by adding another position to be assumed by the volunteers, in concordance with item 3.17 of the \gls{MDS}-\gls{UPDRS}, which is used to assess hand rest tremor,
\item recruiting double the number of volunteers,
\item making the inclusion criteria for the healthy volunteers more strict, ultimately populating an age-matched control group,
\item performing simultaneous \gls{UPDRS} assessments to later examine the correlation between the two methods,
\item collecting longer signals using our tool, going from 10 seconds to 30, 
\item calculating more characteristics from the longer signals,
\item simulating de novo patients' examination by recording data from two \gls{PD} volunteers prior to their medication intake,
\item training and testing a machine learning algorithm to explore how our tool would perform when used to classify as healthy or abnormal, new, unlabeled sensor data. 
\end{itemize}

\noindent
Our protocol design changes for \gls{SmartCT2} in comparison to \gls{SmartCT1} proved to be correct. The results from the data analysis showed that our smartphone-based method correlated well with the \gls{UPDRS}, identified changes during ON-OFF fluctuations for the same patient, and could be used to discriminate unlabeled data. 


%%%%%%%%%%%%%%%%%%%% END OF PENCT %%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conclusion and Research Implications}
\label{subsubsec:PenImplications}

Recent advances in mobile phone technology have placed an impressive array of sensing and communication equipment at the hands of an ever-growing number of people, to the point that they can be considered ubiquitous. As discussed in chapter \ref{ch:autoQuant}, researchers have already done much work, exploring the potential of these devices in medical applications. One of the areas which can be transformed by the availability of what is essentially a cheap, ubiquitous networked sensor, is that of remote diagnosis and continuous monitoring of movement disorders, such as \gls{PD}, through the accurate, objective quantification of many of their symptoms. 

Our clinical trial \gls{SmartCT1} proved the concept of a smartphone-based method for detecting and quantifying the hand tremor associated with movement disorders using signals from the accelerometer and gyroscope embedded in the patient's phone. Our approach was web-based and user-friendly, requiring minimal user interaction. By recruiting twenty subjects divided in two groups, \gls{SmartPD1} consisting of 10 \gls{PD} patients and \gls{SmartH1} consisting of 10 healthy controls, we found that by combining both accelerometer and gyroscope signals, we were able to correctly identify those suffering from hand tremor, using very simple signal metrics ((\ref{eq: magAlpha}), (\ref{eq: magOmega})). 

More specifically, we explored the use of recently-available smartphone technology and JavaScript \gls{API}s for the purpose of quantifying and diagnosing the upper limb postural tremor which is a dominant symptom in \gls{PD}. Our method was based on the use of on-board accelerometer and gyroscope and collect their signals through a web application. Unlike previously proposed approaches (see section \ref{subsec:smartphones}), ours i) was web-based, meaning that the user would simply have to visit a web page without installing software on their phone, or handling the data being collected, and ii) used accelerometer and gyroscope data simultaneously in order to classify patients based on very simple signal metrics and thresholding. The analysis that followed \gls{SmartCT1} showed that by using simple signal processing we could correctly categorize nine of the ten patients, based on the power of their acceleration and rotational velocity signals, or the differences in performance between their two hands. The gyroscope data appeared to be particularly useful in that regard. The results were published in (Kostikis et al, 2011). 

What \gls{SmartCT1} showed was that a smartphone has the potential to be used in a clinical setting, to quantify human upper limb tremor and identify pathological abnormalities. A larger clinical trial was conducted later to validate the approach and further establish each value. \gls{SmartCT2} was designed to offer longer signals from double the number of participants, with simultaneous \gls{UPDRS} logging from the same exert neurologist, to avoid inter-rater variability. Upon completion of the study, the first test we conducted was that of the correlation between our method of evaluating tremor and the ``gold standard'' of the clinical examination, the \gls{UPDRS} ratings (Kostikis et al, 2014). Even though most physicians' scores when using the \gls{UPDRS} follow a logarithmic pattern when compared to the actual tremor amplitude (see section \ref{subsubsec:SmartCT2Correlation}), the results were promising, particularly regarding the resting tremor testing protocol (following the directions for rating \gls{MDS}-\gls{UPDRS} item 3.17), with Pearson correlation coefficient values in the range of $0.69 - 0.88$, with nearly zero $p$ values. Although we do not advocate the replacement of the \gls{UPDRS} clinical test, we were interested in using the sensors of a ubiquitous device to assist the physician, providing him with an objective method to quantify resting hand tremor efficiently, accurately and remotely. 

By further analyzing the data collected from \gls{SmartCT2} we were able to propose a method to quantify \gls{PD} induced hand tremor. We incorporated an ensemble of decision trees as a machine learning model and we were able to positively identify 82\% of our \gls{PD} volunteers and 90\% of the healthy volunteers (Kostikis et al, 2015). Although both our clinical trials were relatively small, they served as proof of concept and offered encouraging results. The statistical analyses we conducted showed that our proposed method could be used both in a clinical setting to facilitate the physician's work by offering an accurate assessment tool, and at home by the patients themselves to self-monitor their progress. 

The availability of such a ubiquitous assessment tool of an otherwise subjectively rated symptom, such as hand tremor, primarily assists the physician in planning an effective treatment regimen. However, the ability to easily measure hand tremor daily at home by means of the method proposed and storing the relevant metrics in order to later track and visualize the progression of the disease and the effectiveness of the medication is more than welcome as a benefit for the patient himself. Finally, biobanking large data sets with motor information collected according to a specific protocol is something the scientific community could harvest and conduct valuable research on. Our motion monitoring apparatus, combined with signal processing and machine learning could detect motor abnormalities in a non-invasive manner and assist in the diagnosis and long-term improvement of quality of life for PD patients. 

%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>
%%------------------------------------------------------------------------------------>>>>>>>>>>>>>>>>>>>>>>>>>>>